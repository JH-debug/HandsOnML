{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\n",
      "  Downloading https://files.pythonhosted.org/packages/72/0c/173ac467d0a53e33e41b521e4ceba74a8ac7c7873d7b857a8fbdca88302d/bayesian-optimization-1.0.1.tar.gz\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages (from bayesian-optimization) (1.17.2)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages (from bayesian-optimization) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages (from bayesian-optimization) (0.21.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.13.2)\n",
      "Building wheels for collected packages: bayesian-optimization\n",
      "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.0.1-cp37-none-any.whl size=10032 sha256=444d9a35b93b71a507c7b5b38d9e91bbe29f2c018b903b7e2ce4e7994653e635\n",
      "  Stored in directory: /Users/ieunpyo/Library/Caches/pip/wheels/1d/0d/3b/6b9d4477a34b3905f246ff4e7acf6aafd4cc9b77d473629b77\n",
      "Successfully built bayesian-optimization\n",
      "Installing collected packages: bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.0.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 고려해볼만한 변수는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_estimators : Number of trees in random forest\n",
    "#### max_features : The number of features to consider when looking for the best split\n",
    "#### max_depth : Maximum number of levels in tree\n",
    "#### min_samples_split : Minimum number of samples required to split a node\n",
    "#### min_samples_leaf : Minimum number of samples required at each leaf node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greed Search 에 필요한 시간이 충분치 않아서 Colab에서 팀원들과 hyperparameter space를 나누어 진행하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators 분배 은표 [10,50] / 창현 [14,45] / 지현 [18,27,41] / 성호 [23,32,36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "work_dir = '/content/drive/My Drive/work/gimhae_fire/'\n",
    "\n",
    "\n",
    "# [10, 14, 18, 23, 27, 32, 36, 41, 45, 50]\n",
    "# n_estimators 은표 [10,50] / 창현 [14,45] / 지현 [18,27,41] / 성호 [23,32,36]\n",
    "n_estimators_list = [10,50]  # 자기가 돌리기로 한 부분을 리스트 형식으로 넣어주세요\n",
    "\n",
    "# n =5 회 반복으로 하겠습니다.\n",
    "n=5\n",
    "\n",
    "\n",
    "Train_X = np.load(work_dir + 'Train_X.npy',allow_pickle=True)\n",
    "Test_X = np.load(work_dir + 'Test_X.npy',allow_pickle=True)\n",
    "Validation_X = np.load(work_dir + 'Validation_X.npy',allow_pickle=True)\n",
    "\n",
    "Train_y = np.load(work_dir  + 'Train_y.npy',allow_pickle=True)\n",
    "Validation_y = np.load(work_dir + 'Validation_y.npy',allow_pickle=True)\n",
    "\n",
    "Train_X.shape\n",
    "\n",
    "\n",
    "# n_estimators : Number of trees in random forest\n",
    "\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 10, stop = 50, num = 10)]\n",
    "\n",
    "# max_features : The number of features to consider when looking for the best split\n",
    "max_features = [int(x) for x in np.linspace(start = 10, stop = 30, num = 5)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10,100, num = 10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# min_samples_leaf : Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 5, 10]\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "                }\n",
    "\n",
    "\n",
    "random_grid\n",
    "\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def hyper_param_f1_score(n,n_estimators, max_features, max_depth, min_samples_leaf) :\n",
    "    rfc = RandomForestClassifier(n_estimators=n_estimators, max_features=max_features, \n",
    "                                 max_depth=max_depth, min_samples_leaf=min_samples_leaf,\n",
    "                                 n_jobs=-1)\n",
    "    f1_score_list=[]\n",
    "    for i in range(n) :\n",
    "        rfc.fit(Train_X,Train_y)\n",
    "        f1_score_list.append(f1_score(rfc.predict(Validation_X),Validation_y))\n",
    "    m = np.mean(f1_score_list)\n",
    "    s = np.std(f1_score_list)\n",
    "    return [n_estimators, max_features, max_depth, min_samples_leaf, n, m,s]\n",
    "    \n",
    "    \n",
    "result= []\n",
    "for n_estimators_temp in n_estimators_list : \n",
    "    for i in range( len(list(ParameterGrid(random_grid)) ) ) :\n",
    "        min_samples_leaf_temp = ParameterGrid(random_grid)[i]['min_samples_leaf']\n",
    "        max_features_temp = ParameterGrid(random_grid)[i]['max_features']\n",
    "        max_depth_temp = ParameterGrid(random_grid)[i]['max_depth']\n",
    "    \n",
    "        result.append(hyper_param_f1_score(n,n_estimators_temp, max_features_temp, max_depth_temp, min_samples_leaf_temp))\n",
    "    \n",
    "\n",
    "np.save(work_dir+'result',result,allow_pickle=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Greed Search 결과부터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_10_50 = np.load('/Users/ieunpyo/PycharmProjects/Kaggle/gimhae_fire/result_10_50.npy',allow_pickle=True)\n",
    "result_14_45 = np.load('/Users/ieunpyo/PycharmProjects/Kaggle/gimhae_fire/result_14_45.npy',allow_pickle=True)\n",
    "result_18_27_41 = np.load('/Users/ieunpyo/PycharmProjects/Kaggle/gimhae_fire/result_18_27_41.npy',allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_10_14_18_27_41_45_50 = np.r_[result_10_50,result_14_45,result_18_27_41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_10_14_18_27_41_45_50_pd = pd.DataFrame(result_10_14_18_27_41_45_50,columns=['n_estimators', 'max_features', 'max_depth', 'min_samples_leaf', 'n', 'mean','std'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>n</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1055</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.392934</td>\n",
       "      <td>0.0158199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1086</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.391899</td>\n",
       "      <td>0.012256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.391536</td>\n",
       "      <td>0.00797163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.39129</td>\n",
       "      <td>0.0172644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1462</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.39097</td>\n",
       "      <td>0.0192686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1766</td>\n",
       "      <td>41</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.389622</td>\n",
       "      <td>0.0109563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.389405</td>\n",
       "      <td>0.0196752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1716</td>\n",
       "      <td>41</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.38921</td>\n",
       "      <td>0.00812536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>891</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.388652</td>\n",
       "      <td>0.00823097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.388086</td>\n",
       "      <td>0.0157549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>931</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.388048</td>\n",
       "      <td>0.00904918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1821</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.387489</td>\n",
       "      <td>0.0115361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1187</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.387272</td>\n",
       "      <td>0.0145653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.387202</td>\n",
       "      <td>0.0243454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.386928</td>\n",
       "      <td>0.00812982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1066</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.386895</td>\n",
       "      <td>0.0142553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>541</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.386821</td>\n",
       "      <td>0.00750924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.386694</td>\n",
       "      <td>0.0126048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1031</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.386591</td>\n",
       "      <td>0.00471278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1556</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.386109</td>\n",
       "      <td>0.0127435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_estimators max_features max_depth min_samples_leaf  n      mean  \\\n",
       "1055           45           15       100                1  5  0.392934   \n",
       "1086           45           20      None                2  5  0.391899   \n",
       "320            50           30        20                1  5  0.391536   \n",
       "995            45           30        70                1  5   0.39129   \n",
       "1462           27           20        40                4  5   0.39097   \n",
       "1766           41           25        50                2  5  0.389622   \n",
       "910            45           20        40                1  5  0.389405   \n",
       "1716           41           25        30                2  5   0.38921   \n",
       "891            45           25        30                2  5  0.388652   \n",
       "960            45           20        60                1  5  0.388086   \n",
       "931            45           15        50                2  5  0.388048   \n",
       "1821           41           30        70                2  5  0.387489   \n",
       "1187           18           20        40                4  5  0.387272   \n",
       "386            50           20        50                2  5  0.387202   \n",
       "940            45           25        50                1  5  0.386928   \n",
       "1066           45           25       100                2  5  0.386895   \n",
       "541            50           25      None                2  5  0.386821   \n",
       "1625           27           10      None                1  5  0.386694   \n",
       "1031           45           15        90                2  5  0.386591   \n",
       "1556           27           15        80                2  5  0.386109   \n",
       "\n",
       "             std  \n",
       "1055   0.0158199  \n",
       "1086    0.012256  \n",
       "320   0.00797163  \n",
       "995    0.0172644  \n",
       "1462   0.0192686  \n",
       "1766   0.0109563  \n",
       "910    0.0196752  \n",
       "1716  0.00812536  \n",
       "891   0.00823097  \n",
       "960    0.0157549  \n",
       "931   0.00904918  \n",
       "1821   0.0115361  \n",
       "1187   0.0145653  \n",
       "386    0.0243454  \n",
       "940   0.00812982  \n",
       "1066   0.0142553  \n",
       "541   0.00750924  \n",
       "1625   0.0126048  \n",
       "1031  0.00471278  \n",
       "1556   0.0127435  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_10_14_18_27_41_45_50_pd.sort_values(by='mean',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## second search\n",
    "##### hyperparameter & fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/Users/ieunpyo/PycharmProjects/Kaggle/gimhae_fire/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1_best = 0\n",
    "i = 0 \n",
    "for i in range(100) : \n",
    "    # randomly select hyperparameters within reasonable range\n",
    "    \n",
    "    #n_estimators\n",
    "    n_estimators_temp = np.random.randint(40,55)\n",
    "    #max_features\n",
    "    max_features_temp = np.random.randint(15,35)\n",
    "    #min_sample_leaf\n",
    "    min_sample_leaf_temp = np.random.randint(1,5)\n",
    "    #max_depth\n",
    "    max_depth_temp = np.random.randint(20,110)\n",
    "    \n",
    "    # Model\n",
    "    RF_clf = RandomForestClassifier(n_estimators =n_estimators_temp, \n",
    "                            max_features = max_features_temp,\n",
    "                            min_samples_leaf = min_sample_leaf_temp,\n",
    "                            max_depth = max_depth_temp)\n",
    "    \n",
    "    RF_clf.fit(Train_X,Train_y)\n",
    "    \n",
    "    f1 = f1_score( RF_clf.predict(Validation_X), Validation_y ) \n",
    "    \n",
    "    if f1 > f1_best : \n",
    "        # 새로 찍은 RF_clf의 f1 score가 best f1 score보다 높으면\n",
    "        \n",
    "        # 챔피언 바꾸기\n",
    "        RF_clf_best = RF_clf\n",
    "        f1_best = f1\n",
    "        \n",
    "        # 제출형태의 csv 파일로 저장\n",
    "        submission = pd.DataFrame(RF_clf_best.predict(Test_X),columns=['fr_yn'])\n",
    "        submission['fr_yn'] = submission['fr_yn'].map({1:'Y',0:'N'})\n",
    "        now = datetime.datetime.now()\n",
    "        submission.to_csv(save_dir+'화재예측과제_Submission' + '_'+now.strftime('%H:%M:%S') +'.csv',index=False)\n",
    "        \n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_clf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score( RF_clf_best.predict(Validation_X), Validation_y ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict on test_X & submission\n",
    "##### 정해진 hyperparameter로 N번 fitting 반복 predict -> f-score 최고점된 model로 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(RF_clf_best.predict(Test_X),columns=['fr_yn'])\n",
    "submission['fr_yn'] = submission['fr_yn'].map({1:'Y',0:'N'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "submission.to_csv(save_dir+'화재예측과제_Submission' + '_'+now.strftime('%H:%M:%S') +'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
