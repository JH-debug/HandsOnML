{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer,IterativeImputer                          \n",
    "\n",
    "from sklearn.compose import ColumnTransformer,make_column_transformer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (8,172,173,174,175,176,177,178,179) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "work_dir = '/Users/ieunpyo/PycharmProjects/Kaggle/gimhae_fire/'\n",
    "\n",
    "train = pd.read_csv((work_dir + 'PJT002_train.csv'),encoding='utf-8' )\n",
    "validation = pd.read_csv((work_dir + 'PJT002_validation .csv'),encoding='utf-8' )\n",
    "test = pd.read_csv((work_dir + '/' + 'PJT002_test.csv'),encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature List\n",
    "\n",
    "* date_ var : 'date_of_fr'\n",
    "\n",
    "* y_var : 'fr_yn'\n",
    "\n",
    "* weather var : 'tmprtr','prcpttn','wnd_spd','wnd_drctn','hmdt'\n",
    "\n",
    "* land_var : 'jmk','rgnl_ar_nm','rgnl_ar_nm2','lnd_us_sttn_nm','rd_sd_nm'\n",
    "\n",
    "\n",
    "\n",
    "* 성호님 변수 :'fr_sttn_dstnc','bldng_ar_prc','fr_wthr_fclt_dstnc','fr_mn_cnt','mlt_us_yn','cctv_dstnc','fr_wthr_fclt_in_100m','cctv_in_100m',\n",
    "'tbc_rtl_str_dstnc','sft_emrgnc_bll_dstnc','ahsm_dstnc','no_tbc_zn_dstnc','bldng_cnt_in_50m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date 변수 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_of_fr_transform(df) :\n",
    "    year_list = []\n",
    "    month_list =  []\n",
    "    day_list = []\n",
    "    weekday_list = []\n",
    "    hour_list = []\n",
    "    \n",
    "    season_list = []\n",
    "    \n",
    "    for i in range(len(df)) : \n",
    "        date_0=train.dt_of_fr[i].split(' ')[0] # '2017-10-20'\n",
    "        time_0=train.dt_of_fr[i].split(' ')[1] # '05:54:00'\n",
    "        \n",
    "        year = int(date_0.split('-')[0]) # 2017\n",
    "        month = int(date_0.split('-')[1]) # 10\n",
    "        day = int(date_0.split('-')[2]) # 20\n",
    "        weekday = datetime.date(year,month,day).weekday() # 0 : 월~ 6 : 일\n",
    "        \n",
    "        hour = int(time_0.split(':')[0]) # 05\n",
    "        \n",
    "        \n",
    "        if month in [3,4,5] :\n",
    "            season = 0\n",
    "        elif month in [6,7,8] :\n",
    "            season = 1\n",
    "        elif month in [9,10,11] :\n",
    "            season = 2 \n",
    "        else :\n",
    "            season =3\n",
    "            \n",
    "        year_list.append(year)\n",
    "        month_list.append(month)\n",
    "        day_list.append(day)\n",
    "        weekday_list.append(weekday)\n",
    "        season_list.append(season)\n",
    "        \n",
    "        hour_list.append(hour)\n",
    "        \n",
    "    df['year'] = year_list\n",
    "    df['month'] = month_list\n",
    "    df['day'] = day_list\n",
    "    df['weekday'] = weekday_list\n",
    "    df['season'] = season_list\n",
    "    df['hour'] = hour_list\n",
    "    # 다른 분들이 dt_of_fr 쓰실지 몰라서 일단은 drop 보류.\n",
    "    # df = df.drop(['dt_of_fr'],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 적용\n",
    "train = dt_of_fr_transform(train)\n",
    "test = dt_of_fr_transform(test)\n",
    "validation = dt_of_fr_transform(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fr_yn 변수 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['fr_yn'] = pd.get_dummies(train['fr_yn'])['Y']\n",
    "validation['fr_yn'] = pd.get_dummies(validation['fr_yn'])['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather 변수 처리\n",
    "\n",
    "##### 'tmprtr','prcpttn','wnd_spd','wnd_drctn','hmdt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 이 중 변수를 제거하고 싶으면 여기 리스트에서 이름을 삭제하면 된다.\n",
    "# pipeline 안에 넣고 싶었지만 변수를 중간에 제거하는 것은 파이프라인에 안 들어간다. 도저히... 안된다고 한다...\n",
    "weather_var_1 = ['prcpttn']\n",
    "weather_var_2 = ['tmprtr','wnd_spd','wnd_drctn','hmdt'] \n",
    "weather_var = weather_var_1 + weather_var_2\n",
    "\n",
    "weather_imputer = ColumnTransformer([\n",
    "    ('prcpttn_imputer',SimpleImputer(strategy='constant',fill_value=-1),weather_var_1),\n",
    "    ('otehrs_imputer',IterativeImputer(),weather_var_2)\n",
    "     ])\n",
    "\n",
    "weather_scale_PCA = Pipeline([\n",
    "    ('Scaler',StandardScaler()),\n",
    "    ('PCA',PCA())\n",
    "])\n",
    "\n",
    "weather_pipe = Pipeline([\n",
    "    ('weather_imputer',weather_imputer),\n",
    "    ('weather_scale_PCA',weather_scale_PCA)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.83696482, -0.06593299,  0.27633869, -1.05562882, -0.48734151],\n",
       "       [ 1.27023595, -0.08216013, -0.70304549,  0.42325286,  0.22044418],\n",
       "       [-1.04874847, -0.52521494, -0.44697804,  1.40230662,  0.76804871],\n",
       "       ...,\n",
       "       [-1.28843737,  0.21226355, -0.011177  ,  0.03247435, -0.63159873],\n",
       "       [ 0.11110034,  1.62059609,  0.87102948, -1.51675953,  0.06328016],\n",
       "       [ 0.78164759,  0.23277003, -0.15921767, -0.97506574, -0.14958609]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_pipe.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94063744, -0.4778311 , -0.15723154,  0.51032937, -0.22702357],\n",
       "       [ 1.98512404, -0.40265732,  0.06949097, -0.13068358, -0.51807421],\n",
       "       [-0.55312867, -0.24893418,  1.63349464, -0.3584252 , -0.2100535 ],\n",
       "       ...,\n",
       "       [ 1.57226778,  0.64638803, -0.72067563, -0.34062055, -0.40175184],\n",
       "       [-2.23494975, -0.18298893,  1.20507098,  0.56197559, -0.24398495],\n",
       "       [-0.91382092,  0.26806252,  0.48812327, -0.50571881, -0.69183157]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_pipe.fit_transform(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.43852422e+00,  2.73587519e-01, -4.29375211e-01,\n",
       "         6.60203901e-01, -2.84419342e-03],\n",
       "       [ 4.43239039e-01, -3.67840424e-01, -2.65739699e-01,\n",
       "         7.84402750e-01, -3.33679053e-01],\n",
       "       [ 1.24490978e+00,  4.43525516e+00,  2.77708068e+00,\n",
       "         3.99014900e-01,  2.06565294e-01],\n",
       "       ...,\n",
       "       [ 4.05699582e-02,  1.39168587e+00, -4.41421700e-01,\n",
       "        -1.08893974e+00, -3.34892652e-01],\n",
       "       [ 6.59174478e-01, -5.13874661e-01, -6.38967952e-01,\n",
       "         7.30574041e-01,  7.44641823e-01],\n",
       "       [ 2.03829082e+00, -2.57184386e-01, -3.26852698e-01,\n",
       "        -5.11989832e-01,  1.48018455e-03]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_pipe.fit_transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## land 변수 처리\n",
    "\n",
    "#####  'rgnl_ar_nm','rgnl_ar_nm2','jmk','lnd_us_sttn_nm','rd_sd_nm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'rgnl_ar_nm','rgnl_ar_nm2','jmk','lnd_us_sttn_nm','rd_sd_nm' 공통"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def land_transform_step_1(df) :\n",
    "    # rgnl_ar_nm, rgnl_ar_nm, jmk,lnd_us_sttn_nm,rd_sd_nm 행의 NA 값들을 모두 'blank'라는 새로운 범주로 지정해줌\n",
    "    # (참고로 rgnl_ar_nm 이 NA인 경우 모두 rgnl_ar_nm2 값 또한 NA)\n",
    "    values = {'rgnl_ar_nm': 'blank', 'rgnl_ar_nm2': 'blank','jmk':'blank','lnd_us_sttn_nm':'blank','rd_sd_nm':'blank'}\n",
    "    df = df.fillna(value=values)\n",
    "    \n",
    "    # rgnl_ar_nm2 처리1 : rgnl_ar_nm2가 지정되지 않은 경우 그 행의 rgnl_ar_nm1의 값을 따르게 함.\n",
    "    ix = df[ df['rgnl_ar_nm2']=='지정되지않음' ].index\n",
    "    df.loc[ix,'rgnl_ar_nm2'] = df.loc[ix,'rgnl_ar_nm']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = land_transform_step_1(train)\n",
    "test = land_transform_step_1(test)\n",
    "validation = land_transform_step_1(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['자연녹지지역']\n",
      " ['계획관리지역']\n",
      " ['제2종일반주거지역']\n",
      " ['제1종일반주거지역']\n",
      " ['자연환경보전지역']\n",
      " ['보전관리지역']\n",
      " ['일반상업지역']\n",
      " ['생산관리지역']\n",
      " ['준주거지역']\n",
      " ['생산녹지지역']\n",
      " ['농림지역']\n",
      " ['blank']\n",
      " ['준공업지역']\n",
      " ['일반공업지역']\n",
      " ['근린상업지역']\n",
      " ['제1종전용주거지역']\n",
      " ['개발제한구역']\n",
      " ['제3종일반주거지역']\n",
      " ['제2종전용주거지역']\n",
      " ['보전녹지지역']\n",
      " ['유통상업지역']\n",
      " ['중심상업지역']\n",
      " ['관리지역']\n",
      " ['용도미지정']]\n",
      "[['대']\n",
      " ['답']\n",
      " ['임']\n",
      " ['종']\n",
      " ['장']\n",
      " ['전']\n",
      " ['잡']\n",
      " ['목']\n",
      " ['도']\n",
      " ['천']\n",
      " ['양']\n",
      " ['구']\n",
      " ['과']\n",
      " ['체']\n",
      " ['창']\n",
      " ['학']\n",
      " ['원']\n",
      " ['공']\n",
      " ['유']\n",
      " ['수']\n",
      " ['주']\n",
      " ['철']\n",
      " ['묘']\n",
      " ['제']\n",
      " ['차']\n",
      " ['사']]\n",
      "[['단독']\n",
      " ['연립']\n",
      " ['자연림']\n",
      " ['주거기타']\n",
      " ['아파트']\n",
      " ['상업용']\n",
      " ['주거나지']\n",
      " ['공업용']\n",
      " ['답']\n",
      " ['업무용']\n",
      " ['주상용']\n",
      " ['주상나지']\n",
      " ['전기타']\n",
      " ['위험시설']\n",
      " ['전']\n",
      " ['조림']\n",
      " ['blank']\n",
      " ['답기타']\n",
      " ['과수원']\n",
      " ['토지임야']\n",
      " ['공업기타']\n",
      " ['골프장 회원제']\n",
      " ['주상기타']\n",
      " ['다세대']\n",
      " ['도로등']\n",
      " ['상업기타']\n",
      " ['임야기타']\n",
      " ['유원지']\n",
      " ['운동장등']\n",
      " ['공원등']\n",
      " ['하천등']\n",
      " ['유해.혐오시설']\n",
      " ['공업나지']\n",
      " ['기타']\n",
      " ['상업나지']\n",
      " ['주차장등']\n",
      " ['목장용지']\n",
      " ['여객자동차터미널']\n",
      " ['고속도로휴게소']\n",
      " ['스키장']\n",
      " ['특수기타']\n",
      " ['콘도미니엄']\n",
      " ['공원묘지']\n",
      " ['골프장 대중제']\n",
      " ['발전소']\n",
      " ['경마장']]\n",
      "[['세로한면(불)']\n",
      " ['세로한면(가)']\n",
      " ['중로한면']\n",
      " ['소로한면']\n",
      " ['맹지']\n",
      " ['광대로한면']\n",
      " ['세로각지(불)']\n",
      " ['중로각지']\n",
      " ['세로각지(가)']\n",
      " ['소로각지']\n",
      " ['blank']\n",
      " ['광대세각']\n",
      " ['광대소각']\n",
      " ['지정되지않음']]\n"
     ]
    }
   ],
   "source": [
    "# train, test, validation set마다 포함하고 있는 범주가 조금씩 달라서 한번에 묶어서 기준 세움\n",
    "\n",
    "# rgnl_ar_nm, rgnl_ar_nm1 변수의 경우 rgnl_ar_nm_uniques 가지고 fitting하도록 함.\n",
    "rgnl_ar_nm_uniques = train.rgnl_ar_nm.append(train.rgnl_ar_nm2).append(test.rgnl_ar_nm).append(test.rgnl_ar_nm2).append(validation.rgnl_ar_nm).append(validation.rgnl_ar_nm2).unique()\n",
    "rgnl_ar_nm_uniques = rgnl_ar_nm_uniques.reshape(-1,1)\n",
    "\n",
    "# 'jmk','lnd_us_sttn_nm','rd_sd_nm' 또한 마찬가지\n",
    "jmk_uniques = train.jmk.append(test.jmk).append(validation.jmk).unique()\n",
    "jmk_uniques = jmk_uniques.reshape(-1,1)\n",
    "\n",
    "lnd_us_sttn_nm_uniques = train.lnd_us_sttn_nm.append(test.lnd_us_sttn_nm).append(validation.lnd_us_sttn_nm).unique()\n",
    "lnd_us_sttn_nm_uniques = lnd_us_sttn_nm_uniques.reshape(-1,1)\n",
    "\n",
    "rd_sd_nm_uniques = train.rd_sd_nm.append(test.rd_sd_nm).append(validation.rd_sd_nm).unique()\n",
    "rd_sd_nm_uniques = rd_sd_nm_uniques.reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "print(rgnl_ar_nm_uniques)\n",
    "print(jmk_uniques)\n",
    "print(lnd_us_sttn_nm_uniques)\n",
    "print(rd_sd_nm_uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def land_transform_step_2(df):\n",
    "    #################################################################################\n",
    "    # rgnl_ar_nm, rgnl_ar_nm2 처리 \n",
    "    \n",
    "    \n",
    "    # train, test, validation set마다 포함하고 있는 범주가 조금씩 달라서 한번에 묶어서 기준 세움\n",
    "    oh_enc_rgnl_ar_nm = OneHotEncoder()\n",
    "    oh_enc_rgnl_ar_nm.fit(rgnl_ar_nm_uniques)\n",
    "    # category 이름 list\n",
    "    cat_list_rgnl = oh_enc_rgnl_ar_nm.__dict__['categories_']\n",
    "    \n",
    "    # encoder 들어갈 수 있게 모양 잡아줌.\n",
    "    ar1 = np.array(df.rgnl_ar_nm).reshape(-1,1)\n",
    "    ar2 = np.array(df.rgnl_ar_nm).reshape(-1,1)\n",
    "    \n",
    "    # onehot encoding\n",
    "    ar1_onehot = oh_enc_rgnl_ar_nm.transform(ar1)\n",
    "    ar2_onehot = oh_enc_rgnl_ar_nm.transform(ar2)\n",
    "    \n",
    "    # 더해주고 2로 나누고 본 데이터에 붙이고 rgnl_ar_nm, rgnl_ar_nm2 drop\n",
    "    onehot = (ar1_onehot/2+ar2_onehot/2).toarray()\n",
    "    df = df.drop(['rgnl_ar_nm','rgnl_ar_nm2'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(onehot,columns=cat_list_rgnl)],axis=1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = land_transform_step_2(train)\n",
    "test= land_transform_step_2(test)\n",
    "validation = land_transform_step_2(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'jmk','lnd_us_sttn_nm','rd_sd_nm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_left = ['jmk','lnd_us_sttn_nm','rd_sd_nm']\n",
    "\n",
    "land_ohe = ColumnTransformer([\n",
    "    ('land_left_ohe',OneHotEncoder(),land_left)\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "land_ohe.fit_transform(train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
