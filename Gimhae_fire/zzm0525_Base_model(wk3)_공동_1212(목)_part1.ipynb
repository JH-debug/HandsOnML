{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer,IterativeImputer                          \n",
    "\n",
    "from sklearn.compose import ColumnTransformer,make_column_transformer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (8,172,173,174,175,176,177,178,179) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "work_dir = '/Users/ieunpyo/PycharmProjects/Kaggle/gimhae_fire/'\n",
    "\n",
    "train = pd.read_csv((work_dir + 'PJT002_train.csv'),encoding='utf-8' )\n",
    "validation = pd.read_csv((work_dir + 'PJT002_validation .csv'),encoding='utf-8' )\n",
    "test = pd.read_csv((work_dir + '/' + 'PJT002_test.csv'),encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1단계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date 변수 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_of_fr_transform(df) :\n",
    "    year_list = []\n",
    "    month_list =  []\n",
    "    day_list = []\n",
    "    weekday_list = []\n",
    "    hour_list = []\n",
    "    \n",
    "    season_list = []\n",
    "    \n",
    "    for i in range(len(df)) : \n",
    "        date_0=df.dt_of_fr[i].split(' ')[0] # '2017-10-20'\n",
    "        time_0=df.dt_of_fr[i].split(' ')[1] # '05:54:00'\n",
    "        \n",
    "        year = int(date_0.split('-')[0]) # 2017\n",
    "        month = int(date_0.split('-')[1]) # 10\n",
    "        day = int(date_0.split('-')[2]) # 20\n",
    "        weekday = datetime.date(year,month,day).weekday() # 0 : 월~ 6 : 일\n",
    "        \n",
    "        hour = int(time_0.split(':')[0]) # 05\n",
    "        \n",
    "        \n",
    "        if month in [3,4,5] :\n",
    "            season = 0\n",
    "        elif month in [6,7,8] :\n",
    "            season = 1\n",
    "        elif month in [9,10,11] :\n",
    "            season = 2 \n",
    "        else :\n",
    "            season =3\n",
    "            \n",
    "        year_list.append(year)\n",
    "        month_list.append(month)\n",
    "        day_list.append(day)\n",
    "        weekday_list.append(weekday)\n",
    "        season_list.append(season)\n",
    "        \n",
    "        hour_list.append(hour)\n",
    "        \n",
    "    df['year'] = year_list\n",
    "    df['month'] = month_list\n",
    "    df['day'] = day_list\n",
    "    df['weekday'] = weekday_list\n",
    "    df['season'] = season_list\n",
    "    df['hour'] = hour_list\n",
    "    # 다른 분들이 dt_of_fr 쓰실지 몰라서 일단은 drop 보류.\n",
    "    # df = df.drop(['dt_of_fr'],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 적용\n",
    "train = dt_of_fr_transform(train)\n",
    "test = dt_of_fr_transform(test)\n",
    "validation = dt_of_fr_transform(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 위 중에서 month, weekday, season, hour만 살려서 onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 중에서 month, weekday, season, hour만 살린다.\n",
    "date_var = ['month','weekday','season','hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train,columns=date_var)\n",
    "test = pd.get_dummies(test,columns=date_var)\n",
    "validation = pd.get_dummies(validation,columns=date_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fr_yn 변수 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['fr_yn'] = pd.get_dummies(train['fr_yn'])['Y']\n",
    "validation['fr_yn'] = pd.get_dummies(validation['fr_yn'])['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'rgnl_ar_nm','rgnl_ar_nm2','jmk','lnd_us_sttn_nm','rd_sd_nm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def land_transform_step_1(df) :\n",
    "    # rgnl_ar_nm, rgnl_ar_nm, jmk,lnd_us_sttn_nm,rd_sd_nm 행의 NA 값들을 모두 'blank'라는 새로운 범주로 지정해줌\n",
    "    # (참고로 rgnl_ar_nm 이 NA인 경우 모두 rgnl_ar_nm2 값 또한 NA)\n",
    "    values = {'rgnl_ar_nm': 'blank', 'rgnl_ar_nm2': 'blank','jmk':'blank','lnd_us_sttn_nm':'blank','rd_sd_nm':'blank'}\n",
    "    df = df.fillna(value=values)\n",
    "    \n",
    "    # rgnl_ar_nm2 처리1 : rgnl_ar_nm2가 지정되지 않은 경우 그 행의 rgnl_ar_nm1의 값을 따르게 함.\n",
    "    ix = df[ df['rgnl_ar_nm2']=='지정되지않음' ].index\n",
    "    df.loc[ix,'rgnl_ar_nm2'] = df.loc[ix,'rgnl_ar_nm']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = land_transform_step_1(train)\n",
    "test = land_transform_step_1(test)\n",
    "validation = land_transform_step_1(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(rgnl_ar_nm_uniques)\\nprint(jmk_uniques)\\nprint(lnd_us_sttn_nm_uniques)\\nprint(rd_sd_nm_uniques)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, test, validation set마다 포함하고 있는 범주가 조금씩 달라서 한번에 묶어서 기준 세움\n",
    "\n",
    "# rgnl_ar_nm, rgnl_ar_nm2 변수의 경우 rgnl_ar_nm_uniques 가지고 fitting하도록 함.\n",
    "rgnl_ar_nm_uniques = train.rgnl_ar_nm.append(train.rgnl_ar_nm2).append(test.rgnl_ar_nm).append(test.rgnl_ar_nm2).append(validation.rgnl_ar_nm).append(validation.rgnl_ar_nm2).unique()\n",
    "rgnl_ar_nm_uniques = rgnl_ar_nm_uniques.reshape(-1,1)\n",
    "\n",
    "# 'jmk','lnd_us_sttn_nm','rd_sd_nm' 또한 마찬가지\n",
    "jmk_uniques = train.jmk.append(test.jmk).append(validation.jmk).unique()\n",
    "jmk_uniques = jmk_uniques.reshape(-1,1)\n",
    "\n",
    "lnd_us_sttn_nm_uniques = train.lnd_us_sttn_nm.append(test.lnd_us_sttn_nm).append(validation.lnd_us_sttn_nm).unique()\n",
    "lnd_us_sttn_nm_uniques = lnd_us_sttn_nm_uniques.reshape(-1,1)\n",
    "\n",
    "rd_sd_nm_uniques = train.rd_sd_nm.append(test.rd_sd_nm).append(validation.rd_sd_nm).unique()\n",
    "rd_sd_nm_uniques = rd_sd_nm_uniques.reshape(-1,1)\n",
    "\n",
    "'''\n",
    "print(rgnl_ar_nm_uniques)\n",
    "print(jmk_uniques)\n",
    "print(lnd_us_sttn_nm_uniques)\n",
    "print(rd_sd_nm_uniques)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def land_transform_step_2(df):\n",
    "    #################################################################################\n",
    "    # rgnl_ar_nm, rgnl_ar_nm2 처리 \n",
    "    # train, test, validation set마다 포함하고 있는 범주가 조금씩 달라서 한번에 묶어서 기준 세움\n",
    "    \n",
    "    oh_enc_rgnl_ar_nm = OneHotEncoder()\n",
    "    oh_enc_rgnl_ar_nm.fit(rgnl_ar_nm_uniques)\n",
    "    \n",
    "    # category 이름 list\n",
    "    cat_list_rgnl = oh_enc_rgnl_ar_nm.__dict__['categories_'][0].tolist()\n",
    "    \n",
    "    # encoder 들어갈 수 있게 모양 잡아줌.\n",
    "    ar1 = np.array(df.rgnl_ar_nm).reshape(-1,1)\n",
    "    ar2 = np.array(df.rgnl_ar_nm2).reshape(-1,1)\n",
    "    \n",
    "    # onehot encoding\n",
    "    ar1_onehot = oh_enc_rgnl_ar_nm.transform(ar1)\n",
    "    ar2_onehot = oh_enc_rgnl_ar_nm.transform(ar2)\n",
    "    \n",
    "    # 더해주고 2로 나누고 본 데이터에 붙이고 rgnl_ar_nm, rgnl_ar_nm2 drop\n",
    "    onehot = (ar1_onehot/2+ar2_onehot/2).toarray()\n",
    "    df = df.drop(['rgnl_ar_nm','rgnl_ar_nm2'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(onehot,columns=cat_list_rgnl)],axis=1)\n",
    "    \n",
    "    #################################################################################\n",
    "    # jmk, lnd_us_sttn_nm, rd_sd_nm 처리\n",
    "    # 위와 같은 방법\n",
    "    \n",
    "    # jmk\n",
    "    oh_enc_jmk = OneHotEncoder()\n",
    "    oh_enc_jmk.fit(jmk_uniques)\n",
    "    \n",
    "    cat_list_jmk = oh_enc_jmk.__dict__['categories_'][0].tolist()\n",
    "    jmk_arr = np.array(df.jmk).reshape(-1,1)\n",
    "    jmk_onehot = oh_enc_jmk.transform(jmk_arr).toarray()\n",
    "    df = df.drop(['jmk'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(jmk_onehot,columns=cat_list_jmk)],axis=1)\n",
    "    \n",
    "    #lnd_us_sttn_nm\n",
    "    oh_enc_lnd_us_sttn_nm = OneHotEncoder()\n",
    "    oh_enc_lnd_us_sttn_nm.fit(lnd_us_sttn_nm_uniques)\n",
    "\n",
    "    cat_list_lnd_us_sttn_nm = oh_enc_lnd_us_sttn_nm.__dict__['categories_'][0].tolist()\n",
    "    lnd_us_sttn_nm_arr = np.array(df.lnd_us_sttn_nm).reshape(-1,1)\n",
    "    lnd_us_sttn_nm_onehot = oh_enc_lnd_us_sttn_nm.transform(lnd_us_sttn_nm_arr).toarray()\n",
    "    df = df.drop(['lnd_us_sttn_nm'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(lnd_us_sttn_nm_onehot,columns=cat_list_lnd_us_sttn_nm)],axis=1)\n",
    "    \n",
    "    #rd_sd_nm\n",
    "    oh_enc_rd_sd_nm = OneHotEncoder()\n",
    "    oh_enc_rd_sd_nm.fit(rd_sd_nm_uniques)\n",
    "    \n",
    "    cat_list_rd_sd_nm = oh_enc_rd_sd_nm.__dict__['categories_'][0].tolist()\n",
    "    rd_sd_nm_arr = np.array(df.rd_sd_nm).reshape(-1,1)\n",
    "    rd_sd_nm_onehot = oh_enc_rd_sd_nm.transform(rd_sd_nm_arr).toarray()\n",
    "    df = df.drop(['rd_sd_nm'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(rd_sd_nm_onehot,columns=cat_list_rd_sd_nm)],axis=1)\n",
    "\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = land_transform_step_2(train)\n",
    "test= land_transform_step_2(test)\n",
    "validation = land_transform_step_2(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지현님 파트(1단계)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 건물 승인일자 년 단위로 자르기 함수 (소수점 포함 10자리인 글자만 찾아 자르기)\n",
    "\n",
    "* 그 후, 2019에서 뺀 값으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_func(x):\n",
    "    if len(str(x)) == 10:\n",
    "        return str(x)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dt_of_athrztn'] = train['dt_of_athrztn'].apply(cut_func)\n",
    "test['dt_of_athrztn'] = test['dt_of_athrztn'].apply(cut_func)\n",
    "validation['dt_of_athrztn'] = validation['dt_of_athrztn'].apply(cut_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dt_of_athrztn'] = pd.to_numeric(train['dt_of_athrztn'])\n",
    "test['dt_of_athrztn'] = pd.to_numeric(test['dt_of_athrztn'])\n",
    "validation['dt_of_athrztn'] = pd.to_numeric(validation['dt_of_athrztn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dt_of_athrztn'] = 2019 - train['dt_of_athrztn']\n",
    "test['dt_of_athrztn'] = 2019 - test['dt_of_athrztn']\n",
    "validation['dt_of_athrztn'] = 2019 - validation['dt_of_athrztn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 지상층, 지하층, 건물채수 카테고리화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [train, test, validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지상층 카테고리화\n",
    "\n",
    "for dataset in train_data:\n",
    "    dataset.loc[dataset['ttl_grnd_flr'] == 0, 'ttl_grnd_flr'] = 0,\n",
    "    dataset.loc[(dataset['ttl_grnd_flr'] >= 1) &  (dataset['ttl_grnd_flr'] <= 10), 'ttl_grnd_flr'] = 10, \n",
    "    dataset.loc[(dataset['ttl_grnd_flr'] > 10) &  (dataset['ttl_grnd_flr'] <= 20), 'ttl_grnd_flr'] = 20,\n",
    "    dataset.loc[(dataset['ttl_grnd_flr'] > 20) &  (dataset['ttl_grnd_flr'] <= 30), 'ttl_grnd_flr'] = 30,\n",
    "    dataset.loc[(dataset['ttl_grnd_flr'] > 30) &  (dataset['ttl_grnd_flr'] <= 40), 'ttl_grnd_flr'] = 40,\n",
    "    dataset.loc[(dataset['ttl_grnd_flr'] > 40) &  (dataset['ttl_grnd_flr'] <= 55), 'ttl_grnd_flr'] = 55,\n",
    "    dataset.loc[dataset['ttl_grnd_flr'] > 55, 'ttl_grnd_flr'] = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지하층 카테고리화\n",
    "\n",
    "for dataset in train_data:\n",
    "    dataset.loc[dataset['ttl_dwn_flr'] == 0, 'ttl_dwn_flr'] = 0,\n",
    "    dataset.loc[(dataset['ttl_dwn_flr'] >= 1) &  (dataset['ttl_dwn_flr'] <= 4), 'ttl_dwn_flr'] = 4, \n",
    "    dataset.loc[(dataset['ttl_dwn_flr'] > 4) &  (dataset['ttl_dwn_flr'] <= 10), 'ttl_dwn_flr'] = 10,\n",
    "    dataset.loc[(dataset['ttl_dwn_flr'] > 10) &  (dataset['ttl_dwn_flr'] <= 20), 'ttl_dwn_flr'] = 20,\n",
    "    dataset.loc[dataset['ttl_dwn_flr'] > 20, 'ttl_dwn_flr'] = 21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 건물 채수 카테고리화\n",
    "\n",
    "for dataset in train_data:\n",
    "    dataset.loc[dataset['bldng_cnt'] == 0, 'bldng_cnt'] = 0,\n",
    "    dataset.loc[(dataset['bldng_cnt'] >= 1) &  (dataset['bldng_cnt'] <= 5), 'bldng_cnt'] = 5, \n",
    "    dataset.loc[(dataset['bldng_cnt'] > 5) &  (dataset['bldng_cnt'] <= 10), 'bldng_cnt'] = 10,\n",
    "    dataset.loc[(dataset['bldng_cnt'] > 10) &  (dataset['bldng_cnt'] <= 20), 'bldng_cnt'] = 20,\n",
    "    dataset.loc[(dataset['bldng_cnt'] > 20) &  (dataset['bldng_cnt'] <= 30), 'bldng_cnt'] = 30,\n",
    "    dataset.loc[dataset['bldng_cnt'] > 30, 'bldng_cnt'] = 31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the NA values to 'blank' and -999\n",
    "\n",
    "train[['bldng_us', 'bldng_archtctr', 'bldng_us_clssfctn']] = train[['bldng_us', 'bldng_archtctr', 'bldng_us_clssfctn']].fillna('blank')\n",
    "test[['bldng_us', 'bldng_archtctr', 'bldng_us_clssfctn']] = test[['bldng_us', 'bldng_archtctr', 'bldng_us_clssfctn']].fillna('blank')\n",
    "validation[['bldng_us', 'bldng_archtctr', 'bldng_us_clssfctn']] = validation[['bldng_us', 'bldng_archtctr', 'bldng_us_clssfctn']].fillna('blank')\n",
    "\n",
    "train[['ttl_grnd_flr', 'ttl_dwn_flr', 'bldng_cnt']] = train[['ttl_grnd_flr', 'ttl_dwn_flr', 'bldng_cnt']].fillna(-999)\n",
    "test[['ttl_grnd_flr', 'ttl_dwn_flr', 'bldng_cnt']] = test[['ttl_grnd_flr', 'ttl_dwn_flr', 'bldng_cnt']].fillna(-999)\n",
    "validation[['ttl_grnd_flr', 'ttl_dwn_flr', 'bldng_cnt']] = validation[['ttl_grnd_flr', 'ttl_dwn_flr', 'bldng_cnt']].fillna(-999)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'bldng_us', 'bldng_archtctr', 'bldng_us_clssfctn','ttl_grnd_flr', 'ttl_dwn_flr', 'bldng_cnt'\n",
    "# train, test, validation에서 각각 가지고 있는 총 카테고리의 수가 달라서 묶어서 한번에 피팅해주기로 함.\n",
    "\n",
    "bldng_us_uniques = train.bldng_us.append(train.bldng_us).append(test.bldng_us).append(test.bldng_us).append(validation.bldng_us).append(validation.bldng_us).unique()\n",
    "bldng_us_uniques = bldng_us_uniques.reshape(-1,1)\n",
    "\n",
    "bldng_archtctr_uniques = train.bldng_archtctr.append(train.bldng_archtctr).append(test.bldng_archtctr).append(test.bldng_archtctr).append(validation.bldng_archtctr).append(validation.bldng_archtctr).unique()\n",
    "bldng_archtctr_uniques = bldng_archtctr_uniques.reshape(-1,1)\n",
    "\n",
    "bldng_us_clssfctn_uniques = train.bldng_us_clssfctn.append(train.bldng_us_clssfctn).append(test.bldng_us_clssfctn).append(test.bldng_us_clssfctn).append(validation.bldng_us_clssfctn).append(validation.bldng_us_clssfctn).unique()\n",
    "bldng_us_clssfctn_uniques = bldng_us_clssfctn_uniques.reshape(-1,1)\n",
    "\n",
    "ttl_grnd_flr_uniques = train.ttl_grnd_flr.append(train.ttl_grnd_flr).append(test.ttl_grnd_flr).append(test.ttl_grnd_flr).append(validation.ttl_grnd_flr).append(validation.ttl_grnd_flr).unique()\n",
    "ttl_grnd_flr_uniques = ttl_grnd_flr_uniques.reshape(-1,1)\n",
    "\n",
    "ttl_dwn_flr_uniques = train.ttl_dwn_flr.append(train.ttl_dwn_flr).append(test.ttl_dwn_flr).append(test.ttl_dwn_flr).append(validation.ttl_dwn_flr).append(validation.ttl_dwn_flr).unique()\n",
    "ttl_dwn_flr_uniques = ttl_dwn_flr_uniques.reshape(-1,1)\n",
    "\n",
    "bldng_cnt_uniques = train.bldng_cnt.append(train.bldng_cnt).append(test.bldng_cnt).append(test.bldng_cnt).append(validation.bldng_cnt).append(validation.bldng_cnt).unique()\n",
    "bldng_cnt_uniques = bldng_cnt_uniques.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bldng_transform(df):\n",
    " #################################################################################\n",
    "    # 'bldng_us', 'bldng_archtctr', 'bldng_us_clssfctn','ttl_grnd_flr', 'ttl_dwn_flr', 'bldng_cnt' 처리\n",
    "    # 위와 같은 방법\n",
    "    \n",
    "    # bldng_us\n",
    "    oh_enc_bldng_us = OneHotEncoder()\n",
    "    oh_enc_bldng_us.fit(bldng_us_uniques)\n",
    "    \n",
    "    cat_list_bldng_us = oh_enc_bldng_us.__dict__['categories_'][0].tolist()\n",
    "    bldng_us_arr = np.array(df.bldng_us).reshape(-1,1)\n",
    "    bldng_us_onehot = oh_enc_bldng_us.transform(bldng_us_arr).toarray()\n",
    "    df = df.drop(['bldng_us'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(bldng_us_onehot,columns=cat_list_bldng_us)],axis=1)\n",
    "        \n",
    "    # bldng_archtctr\n",
    "    oh_enc_bldng_archtctr = OneHotEncoder()\n",
    "    oh_enc_bldng_archtctr.fit(bldng_archtctr_uniques)\n",
    "    \n",
    "    cat_list_bldng_archtctr = oh_enc_bldng_archtctr.__dict__['categories_'][0].tolist()\n",
    "    bldng_archtctr_arr = np.array(df.bldng_archtctr).reshape(-1,1)\n",
    "    bldng_archtctr_onehot = oh_enc_bldng_archtctr.transform(bldng_archtctr_arr).toarray()\n",
    "    df = df.drop(['bldng_archtctr'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(bldng_archtctr_onehot,columns=cat_list_bldng_archtctr)],axis=1)\n",
    "    \n",
    "    # bldng_us_clssfctn\n",
    "    oh_enc_bldng_us_clssfctn = OneHotEncoder()\n",
    "    oh_enc_bldng_us_clssfctn.fit(bldng_us_clssfctn_uniques)\n",
    "    \n",
    "    cat_list_bldng_us_clssfctn = oh_enc_bldng_us_clssfctn.__dict__['categories_'][0].tolist()\n",
    "    bldng_us_clssfctn_arr = np.array(df.bldng_us_clssfctn).reshape(-1,1)\n",
    "    bldng_us_clssfctn_onehot = oh_enc_bldng_us_clssfctn.transform(bldng_us_clssfctn_arr).toarray()\n",
    "    df = df.drop(['bldng_us_clssfctn'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(bldng_us_clssfctn_onehot,columns=cat_list_bldng_us_clssfctn)],axis=1)\n",
    "    \n",
    "    # ttl_grnd_flr\n",
    "    oh_enc_ttl_grnd_flr = OneHotEncoder(categories='auto' )\n",
    "    oh_enc_ttl_grnd_flr.fit(ttl_grnd_flr_uniques)\n",
    "    \n",
    "    cat_list_ttl_grnd_flr = oh_enc_ttl_grnd_flr.__dict__['categories_'][0].tolist()\n",
    "    ttl_grnd_flr_arr = np.array(df.ttl_grnd_flr).reshape(-1,1)\n",
    "    ttl_grnd_flr_onehot = oh_enc_ttl_grnd_flr.transform(ttl_grnd_flr_arr).toarray()\n",
    "    df = df.drop(['ttl_grnd_flr'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(ttl_grnd_flr_onehot,columns=cat_list_ttl_grnd_flr)],axis=1)\n",
    "    \n",
    "    # ttl_dwn_flr\n",
    "    oh_enc_ttl_dwn_flr = OneHotEncoder(categories='auto' )\n",
    "    oh_enc_ttl_dwn_flr.fit(ttl_dwn_flr_uniques)\n",
    "    \n",
    "    cat_list_ttl_dwn_flr = oh_enc_ttl_dwn_flr.__dict__['categories_'][0].tolist()\n",
    "    ttl_dwn_flr_arr = np.array(df.ttl_dwn_flr).reshape(-1,1)\n",
    "    ttl_dwn_flr_onehot = oh_enc_ttl_dwn_flr.transform(ttl_dwn_flr_arr).toarray()\n",
    "    df = df.drop(['ttl_dwn_flr'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(ttl_dwn_flr_onehot,columns=cat_list_ttl_dwn_flr)],axis=1)\n",
    "    \n",
    "    # bldng_cnt\n",
    "    oh_enc_bldng_cnt = OneHotEncoder(categories='auto' )\n",
    "    oh_enc_bldng_cnt.fit(bldng_cnt_uniques)\n",
    "    \n",
    "    cat_list_bldng_cnt = oh_enc_bldng_cnt.__dict__['categories_'][0].tolist()\n",
    "    bldng_cnt_arr = np.array(df.bldng_cnt).reshape(-1,1)\n",
    "    bldng_cnt_onehot = oh_enc_bldng_cnt.transform(bldng_cnt_arr).toarray()\n",
    "    df = df.drop(['bldng_cnt'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(bldng_cnt_onehot,columns=cat_list_bldng_cnt)],axis=1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = bldng_transform(train)\n",
    "test = bldng_transform(test)\n",
    "validation = bldng_transform(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성호님 파트\n",
    "\n",
    "* 도시 시골 변수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['emd_nm'] = train['emd_nm'].fillna(value='blank')\n",
    "train.loc[train['emd_nm'].str[5:8].str.endswith('시'), 'urban'] = 'Y'\n",
    "train.loc[train['emd_nm'].str[5:8].str.endswith('군'), 'urban'] = 'N'\n",
    "\n",
    "\n",
    "test['emd_nm'] = test['emd_nm'].fillna(value='blank')\n",
    "test.loc[test['emd_nm'].str.endswith('동'), 'urban'] = 'Y'\n",
    "test.loc[test['emd_nm'].str.endswith('면'), 'urban'] = 'N'\n",
    "test.loc[test['emd_nm'].str.endswith('읍'), 'urban'] = 'N'\n",
    "\n",
    "\n",
    "validation['emd_nm'] = validation['emd_nm'].fillna(value='blank')\n",
    "validation.loc[validation['emd_nm'].str.endswith('동'), 'urban'] = 'Y'\n",
    "validation.loc[validation['emd_nm'].str.endswith('면'), 'urban'] = 'N'\n",
    "validation.loc[validation['emd_nm'].str.endswith('읍'), 'urban'] = 'N'\n",
    "#validation.loc[validation['emd_nm'].str.endswith('k'), 'urban'] = 'blank'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, prefix=['urban'],drop_first=True,columns=['urban'])\n",
    "test = pd.get_dummies(test, prefix=['urban'],drop_first=True,columns=['urban'])\n",
    "validation =pd.get_dummies(validation, prefix=['urban'],drop_first=True,columns=['urban'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sh_var = ['fr_sttn_dstnc', 'bldng_ar_prc', 'fr_wthr_fclt_dstnc', 'fr_mn_cnt', 'mlt_us_yn', 'cctv_dstnc', 'cctv_in_100m', 'fr_wthr_fclt_in_100m', 'tbc_rtl_str_dstnc', \n",
    "               'sft_emrgnc_bll_dstnc', 'ahsm_dstnc', 'no_tbc_zn_dstnc', 'bldng_cnt_in_50m', 'trgt_crtr', 'fr_fghtng_fclt_spcl_css_5_yn', 'fr_fghtng_fclt_spcl_css_6_yn', \n",
    "               'us_yn', 'dngrs_thng_yn', 'slf_fr_brgd_yn', 'blk_dngrs_thng_mnfctr_yn', 'cltrl_hrtg_yn']\n",
    "\n",
    "\n",
    "sh_cat_var = ['mlt_us_yn','trgt_crtr', 'fr_fghtng_fclt_spcl_css_5_yn', 'fr_fghtng_fclt_spcl_css_6_yn', \n",
    "               'us_yn', 'dngrs_thng_yn', 'slf_fr_brgd_yn', 'blk_dngrs_thng_mnfctr_yn', 'cltrl_hrtg_yn'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_cat_var = ['mlt_us_yn','trgt_crtr', 'fr_fghtng_fclt_spcl_css_5_yn', 'fr_fghtng_fclt_spcl_css_6_yn', \n",
    "              'us_yn', 'dngrs_thng_yn', 'slf_fr_brgd_yn', 'blk_dngrs_thng_mnfctr_yn', 'cltrl_hrtg_yn']\n",
    "\n",
    "sh_num_var = ['fr_sttn_dstnc', 'bldng_ar_prc', 'fr_wthr_fclt_dstnc', 'fr_mn_cnt',\n",
    "          'cctv_dstnc', 'cctv_in_100m', 'fr_wthr_fclt_in_100m', 'tbc_rtl_str_dstnc', 'sft_emrgnc_bll_dstnc', \n",
    "          'ahsm_dstnc', 'no_tbc_zn_dstnc', 'bldng_cnt_in_50m']+['hm_cnt']\n",
    "\n",
    "sh_var = sh_cat_var + sh_num_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hm_cnt의 경우도 같이 imputation 해주면 좋을 것 같아서 sh_num_var 에 같이 넣어서 후에 pipeline도 같이 채웠습니다!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성호님 파트 중 categorical data 먼저 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mlt_us_yn', 'trgt_crtr', 'fr_fghtng_fclt_spcl_css_5_yn', 'fr_fghtng_fclt_spcl_css_6_yn', 'us_yn', 'dngrs_thng_yn', 'slf_fr_brgd_yn', 'blk_dngrs_thng_mnfctr_yn', 'cltrl_hrtg_yn']\n"
     ]
    }
   ],
   "source": [
    "print(sh_cat_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the NA values to 'blank'\n",
    "\n",
    "train[sh_cat_var] = train[sh_cat_var].fillna('blank')\n",
    "test[sh_cat_var] = test[sh_cat_var].fillna('blank')\n",
    "validation[sh_cat_var] = validation[sh_cat_var].fillna('blank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt_us_yn_uniques = train.mlt_us_yn.append(train.mlt_us_yn).append(test.mlt_us_yn).append(test.mlt_us_yn).append(validation.mlt_us_yn).append(validation.mlt_us_yn).unique()\n",
    "mlt_us_yn_uniques = mlt_us_yn_uniques.reshape(-1,1)\n",
    "\n",
    "trgt_crtr_uniques = train.trgt_crtr.append(train.trgt_crtr).append(test.trgt_crtr).append(test.trgt_crtr).append(validation.trgt_crtr).append(validation.trgt_crtr).unique()\n",
    "trgt_crtr_uniques = trgt_crtr_uniques.reshape(-1,1)\n",
    "\n",
    "fr_fghtng_fclt_spcl_css_5_yn_uniques = train.fr_fghtng_fclt_spcl_css_5_yn.append(train.fr_fghtng_fclt_spcl_css_5_yn).append(test.fr_fghtng_fclt_spcl_css_5_yn).append(test.fr_fghtng_fclt_spcl_css_5_yn).append(validation.fr_fghtng_fclt_spcl_css_5_yn).append(validation.fr_fghtng_fclt_spcl_css_5_yn).unique()\n",
    "fr_fghtng_fclt_spcl_css_5_yn_uniques = fr_fghtng_fclt_spcl_css_5_yn_uniques.reshape(-1,1)\n",
    "\n",
    "fr_fghtng_fclt_spcl_css_6_yn_uniques = train.fr_fghtng_fclt_spcl_css_6_yn.append(train.fr_fghtng_fclt_spcl_css_6_yn).append(test.fr_fghtng_fclt_spcl_css_6_yn).append(test.fr_fghtng_fclt_spcl_css_6_yn).append(validation.fr_fghtng_fclt_spcl_css_6_yn).append(validation.fr_fghtng_fclt_spcl_css_6_yn).unique()\n",
    "fr_fghtng_fclt_spcl_css_6_yn_uniques = fr_fghtng_fclt_spcl_css_6_yn_uniques.reshape(-1,1)\n",
    "\n",
    "us_yn_uniques = train.us_yn.append(train.us_yn).append(test.us_yn).append(test.us_yn).append(validation.us_yn).append(validation.us_yn).unique()\n",
    "us_yn_uniques = us_yn_uniques.reshape(-1,1)\n",
    "\n",
    "dngrs_thng_yn_uniques = train.dngrs_thng_yn.append(train.dngrs_thng_yn).append(test.dngrs_thng_yn).append(test.dngrs_thng_yn).append(validation.dngrs_thng_yn).append(validation.dngrs_thng_yn).unique()\n",
    "dngrs_thng_yn_uniques = dngrs_thng_yn_uniques.reshape(-1,1)\n",
    "\n",
    "slf_fr_brgd_yn_uniques = train.slf_fr_brgd_yn.append(train.slf_fr_brgd_yn).append(test.slf_fr_brgd_yn).append(test.slf_fr_brgd_yn).append(validation.slf_fr_brgd_yn).append(validation.slf_fr_brgd_yn).unique()\n",
    "slf_fr_brgd_yn_uniques = slf_fr_brgd_yn_uniques.reshape(-1,1)\n",
    "\n",
    "blk_dngrs_thng_mnfctr_yn_uniques = train.blk_dngrs_thng_mnfctr_yn.append(train.blk_dngrs_thng_mnfctr_yn).append(test.blk_dngrs_thng_mnfctr_yn).append(test.blk_dngrs_thng_mnfctr_yn).append(validation.blk_dngrs_thng_mnfctr_yn).append(validation.blk_dngrs_thng_mnfctr_yn).unique()\n",
    "blk_dngrs_thng_mnfctr_yn_uniques = blk_dngrs_thng_mnfctr_yn_uniques.reshape(-1,1)\n",
    "\n",
    "cltrl_hrtg_yn_uniques = train.cltrl_hrtg_yn.append(train.cltrl_hrtg_yn).append(test.cltrl_hrtg_yn).append(test.cltrl_hrtg_yn).append(validation.cltrl_hrtg_yn).append(validation.cltrl_hrtg_yn).unique()\n",
    "cltrl_hrtg_yn_uniques = cltrl_hrtg_yn_uniques.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sh_cat_transform(df):\n",
    " #################################################################################\n",
    " # mlt_us_yn\n",
    "    oh_enc_mlt_us_yn = OneHotEncoder()\n",
    "    oh_enc_mlt_us_yn.fit(mlt_us_yn_uniques)\n",
    "    \n",
    "    cat_list_mlt_us_yn = oh_enc_mlt_us_yn.__dict__['categories_'][0].tolist()\n",
    "    mlt_us_yn_arr = np.array(df.mlt_us_yn).reshape(-1,1)\n",
    "    mlt_us_yn_onehot = oh_enc_mlt_us_yn.transform(mlt_us_yn_arr).toarray()\n",
    "    df = df.drop(['mlt_us_yn'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(mlt_us_yn_onehot,columns=cat_list_mlt_us_yn)],axis=1)\n",
    "\n",
    "    # trgt_crtr\n",
    "    oh_enc_trgt_crtr = OneHotEncoder()\n",
    "    oh_enc_trgt_crtr.fit(trgt_crtr_uniques)\n",
    "    \n",
    "    cat_list_trgt_crtr = oh_enc_trgt_crtr.__dict__['categories_'][0].tolist()\n",
    "    trgt_crtr_arr = np.array(df.trgt_crtr).reshape(-1,1)\n",
    "    trgt_crtr_onehot = oh_enc_trgt_crtr.transform(trgt_crtr_arr).toarray()\n",
    "    df = df.drop(['trgt_crtr'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(trgt_crtr_onehot,columns=cat_list_trgt_crtr)],axis=1)\n",
    "\n",
    "    \n",
    "    # fr_fghtng_fclt_spcl_css_5_yn\n",
    "    oh_enc_fr_fghtng_fclt_spcl_css_5_yn = OneHotEncoder()\n",
    "    oh_enc_fr_fghtng_fclt_spcl_css_5_yn.fit(fr_fghtng_fclt_spcl_css_5_yn_uniques)\n",
    "    \n",
    "    cat_list_fr_fghtng_fclt_spcl_css_5_yn = oh_enc_fr_fghtng_fclt_spcl_css_5_yn.__dict__['categories_'][0].tolist()\n",
    "    fr_fghtng_fclt_spcl_css_5_yn_arr = np.array(df.fr_fghtng_fclt_spcl_css_5_yn).reshape(-1,1)\n",
    "    fr_fghtng_fclt_spcl_css_5_yn_onehot = oh_enc_fr_fghtng_fclt_spcl_css_5_yn.transform(fr_fghtng_fclt_spcl_css_5_yn_arr).toarray()\n",
    "    df = df.drop(['fr_fghtng_fclt_spcl_css_5_yn'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(fr_fghtng_fclt_spcl_css_5_yn_onehot,columns=cat_list_fr_fghtng_fclt_spcl_css_5_yn)],axis=1)\n",
    "\n",
    "    # fr_fghtng_fclt_spcl_css_6_yn\n",
    "    oh_enc_fr_fghtng_fclt_spcl_css_6_yn = OneHotEncoder()\n",
    "    oh_enc_fr_fghtng_fclt_spcl_css_6_yn.fit(fr_fghtng_fclt_spcl_css_6_yn_uniques)\n",
    "    \n",
    "    cat_list_fr_fghtng_fclt_spcl_css_6_yn = oh_enc_fr_fghtng_fclt_spcl_css_6_yn.__dict__['categories_'][0].tolist()\n",
    "    fr_fghtng_fclt_spcl_css_6_yn_arr = np.array(df.fr_fghtng_fclt_spcl_css_6_yn).reshape(-1,1)\n",
    "    fr_fghtng_fclt_spcl_css_6_yn_onehot = oh_enc_fr_fghtng_fclt_spcl_css_6_yn.transform(fr_fghtng_fclt_spcl_css_6_yn_arr).toarray()\n",
    "    df = df.drop(['fr_fghtng_fclt_spcl_css_6_yn'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(fr_fghtng_fclt_spcl_css_6_yn_onehot,columns=cat_list_fr_fghtng_fclt_spcl_css_6_yn)],axis=1)\n",
    "\n",
    "    # us_yn\n",
    "    oh_enc_us_yn = OneHotEncoder()\n",
    "    oh_enc_us_yn.fit(us_yn_uniques)\n",
    "    \n",
    "    cat_list_us_yn = oh_enc_us_yn.__dict__['categories_'][0].tolist()\n",
    "    us_yn_arr = np.array(df.us_yn).reshape(-1,1)\n",
    "    us_yn_onehot = oh_enc_us_yn.transform(us_yn_arr).toarray()\n",
    "    df = df.drop(['us_yn'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(us_yn_onehot,columns=cat_list_us_yn)],axis=1)\n",
    "\n",
    "    # dngrs_thng_yn\n",
    "    oh_enc_dngrs_thng_yn = OneHotEncoder()\n",
    "    oh_enc_dngrs_thng_yn.fit(dngrs_thng_yn_uniques)\n",
    "    \n",
    "    cat_list_dngrs_thng_yn = oh_enc_dngrs_thng_yn.__dict__['categories_'][0].tolist()\n",
    "    dngrs_thng_yn_arr = np.array(df.dngrs_thng_yn).reshape(-1,1)\n",
    "    dngrs_thng_yn_onehot = oh_enc_dngrs_thng_yn.transform(dngrs_thng_yn_arr).toarray()\n",
    "    df = df.drop(['dngrs_thng_yn'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(dngrs_thng_yn_onehot,columns=cat_list_dngrs_thng_yn)],axis=1)\n",
    "\n",
    "    # slf_fr_brgd_yn\n",
    "    oh_enc_slf_fr_brgd_yn = OneHotEncoder()\n",
    "    oh_enc_slf_fr_brgd_yn.fit(slf_fr_brgd_yn_uniques)\n",
    "    \n",
    "    cat_list_slf_fr_brgd_yn = oh_enc_slf_fr_brgd_yn.__dict__['categories_'][0].tolist()\n",
    "    slf_fr_brgd_yn_arr = np.array(df.slf_fr_brgd_yn).reshape(-1,1)\n",
    "    slf_fr_brgd_yn_onehot = oh_enc_slf_fr_brgd_yn.transform(slf_fr_brgd_yn_arr).toarray()\n",
    "    df = df.drop(['slf_fr_brgd_yn'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(slf_fr_brgd_yn_onehot,columns=cat_list_slf_fr_brgd_yn)],axis=1)\n",
    "\n",
    "    # blk_dngrs_thng_mnfctr_yn\n",
    "    oh_enc_blk_dngrs_thng_mnfctr_yn = OneHotEncoder()\n",
    "    oh_enc_blk_dngrs_thng_mnfctr_yn.fit(blk_dngrs_thng_mnfctr_yn_uniques)\n",
    "    \n",
    "    cat_list_blk_dngrs_thng_mnfctr_yn = oh_enc_blk_dngrs_thng_mnfctr_yn.__dict__['categories_'][0].tolist()\n",
    "    blk_dngrs_thng_mnfctr_yn_arr = np.array(df.blk_dngrs_thng_mnfctr_yn).reshape(-1,1)\n",
    "    blk_dngrs_thng_mnfctr_yn_onehot = oh_enc_blk_dngrs_thng_mnfctr_yn.transform(blk_dngrs_thng_mnfctr_yn_arr).toarray()\n",
    "    df = df.drop(['blk_dngrs_thng_mnfctr_yn'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(blk_dngrs_thng_mnfctr_yn_onehot,columns=cat_list_blk_dngrs_thng_mnfctr_yn)],axis=1)\n",
    "\n",
    "   # cltrl_hrtg_yn\n",
    "    oh_enc_cltrl_hrtg_yn = OneHotEncoder()\n",
    "    oh_enc_cltrl_hrtg_yn.fit(cltrl_hrtg_yn_uniques)\n",
    "    \n",
    "    cat_list_cltrl_hrtg_yn = oh_enc_cltrl_hrtg_yn.__dict__['categories_'][0].tolist()\n",
    "    cltrl_hrtg_yn_arr = np.array(df.cltrl_hrtg_yn).reshape(-1,1)\n",
    "    cltrl_hrtg_yn_onehot = oh_enc_cltrl_hrtg_yn.transform(cltrl_hrtg_yn_arr).toarray()\n",
    "    df = df.drop(['cltrl_hrtg_yn'],axis=1)\n",
    "    df = pd.concat([df,pd.DataFrame(cltrl_hrtg_yn_onehot,columns=cat_list_cltrl_hrtg_yn)],axis=1)\n",
    "\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sh_cat_transform(train)\n",
    "validation = sh_cat_transform(validation)\n",
    "test = sh_cat_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59199, 440)\n",
      "(2957, 440)\n",
      "(6898, 440)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성호님 파트 중 numerical data 처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fr_sttn_dstnc', 'bldng_ar_prc', 'fr_wthr_fclt_dstnc', 'fr_mn_cnt', 'cctv_dstnc', 'cctv_in_100m', 'fr_wthr_fclt_in_100m', 'tbc_rtl_str_dstnc', 'sft_emrgnc_bll_dstnc', 'ahsm_dstnc', 'no_tbc_zn_dstnc', 'bldng_cnt_in_50m', 'hm_cnt']\n"
     ]
    }
   ],
   "source": [
    "print (sh_num_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fr_sttn_dstnc</th>\n",
       "      <th>bldng_ar_prc</th>\n",
       "      <th>fr_wthr_fclt_dstnc</th>\n",
       "      <th>fr_mn_cnt</th>\n",
       "      <th>cctv_dstnc</th>\n",
       "      <th>cctv_in_100m</th>\n",
       "      <th>fr_wthr_fclt_in_100m</th>\n",
       "      <th>tbc_rtl_str_dstnc</th>\n",
       "      <th>sft_emrgnc_bll_dstnc</th>\n",
       "      <th>ahsm_dstnc</th>\n",
       "      <th>no_tbc_zn_dstnc</th>\n",
       "      <th>bldng_cnt_in_50m</th>\n",
       "      <th>hm_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133</td>\n",
       "      <td>137.0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1891</td>\n",
       "      <td>29231</td>\n",
       "      <td>11322</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>17360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6388</td>\n",
       "      <td>122581.0</td>\n",
       "      <td>489</td>\n",
       "      <td>85.0</td>\n",
       "      <td>818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4533</td>\n",
       "      <td>20480</td>\n",
       "      <td>3369</td>\n",
       "      <td>7727</td>\n",
       "      <td>0</td>\n",
       "      <td>1791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3340</td>\n",
       "      <td>618105.0</td>\n",
       "      <td>143</td>\n",
       "      <td>137.0</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>31197</td>\n",
       "      <td>12451</td>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "      <td>17285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "      <td>719542.0</td>\n",
       "      <td>1585</td>\n",
       "      <td>176.0</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "      <td>4270</td>\n",
       "      <td>407</td>\n",
       "      <td>508</td>\n",
       "      <td>11</td>\n",
       "      <td>7327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>603</td>\n",
       "      <td>137.0</td>\n",
       "      <td>686</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1702</td>\n",
       "      <td>29778</td>\n",
       "      <td>12487</td>\n",
       "      <td>707</td>\n",
       "      <td>0</td>\n",
       "      <td>17278.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fr_sttn_dstnc  bldng_ar_prc  fr_wthr_fclt_dstnc  fr_mn_cnt  cctv_dstnc  \\\n",
       "0           4547           NaN                 133      137.0         112   \n",
       "1           6388      122581.0                 489       85.0         818   \n",
       "2           3340      618105.0                 143      137.0         165   \n",
       "3            179      719542.0                1585      176.0         131   \n",
       "4           4822           NaN                 603      137.0         686   \n",
       "\n",
       "   cctv_in_100m  fr_wthr_fclt_in_100m  tbc_rtl_str_dstnc  \\\n",
       "0             0                     0               1891   \n",
       "1             0                     0               4533   \n",
       "2             0                     0                277   \n",
       "3             0                     0                438   \n",
       "4             0                     0               1702   \n",
       "\n",
       "   sft_emrgnc_bll_dstnc  ahsm_dstnc  no_tbc_zn_dstnc  bldng_cnt_in_50m  \\\n",
       "0                 29231       11322               88                 0   \n",
       "1                 20480        3369             7727                 0   \n",
       "2                 31197       12451               72                14   \n",
       "3                  4270         407              508                11   \n",
       "4                 29778       12487              707                 0   \n",
       "\n",
       "    hm_cnt  \n",
       "0  17360.0  \n",
       "1   1791.0  \n",
       "2  17285.0  \n",
       "3   7327.0  \n",
       "4  17278.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_plus_validation_sh_num = train[sh_num_var].append(validation[sh_num_var])\n",
    "train_plus_validation_sh_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_sh = IterativeImputer()\n",
    "\n",
    "imputed_sh_num_train_validation=imputer_sh.fit_transform(train_plus_validation_sh_num)\n",
    "imputed_sh_num_test=imputer_sh.transform(test[sh_num_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[sh_num_var]=imputed_sh_num_train_validation[:train.shape[0],:]\n",
    "validation[sh_num_var]=imputed_sh_num_train_validation[train.shape[0]:,:]\n",
    "\n",
    "test[sh_num_var] = imputed_sh_num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59199, 440)\n",
      "(2957, 440)\n",
      "(6898, 440)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2단계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColumnTransformer 위한 변수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_var_1 = ['prcpttn']\n",
    "weather_var_2 = ['tmprtr','wnd_spd','wnd_drctn','hmdt'] \n",
    "weather_var = weather_var_1 + weather_var_2\n",
    "\n",
    "eg_var = train.loc[:,'gas_engry_us_201401':'ele_engry_us_201812'].keys().tolist()\n",
    "lw_var = train.loc[:,'lw_13101010':'lw_13141011'] .keys().tolist()\n",
    "egl_var = eg_var + lw_var # 모든 관심변수들\n",
    "\n",
    "building_numeric_feature = ['bldng_ar', 'ttl_ar', 'lnd_ar']\n",
    "building_date = ['dt_of_athrztn']\n",
    "\n",
    "\n",
    "\n",
    "numerical_feature = ['hm_cnt', 'ahsm_dstnc', 'no_tbc_zn_dstnc', 'bldng_cnt_in_50m']\n",
    "price_feature = ['bldng_ar_prc']\n",
    "\n",
    "date_var = date_var # to be one-hot coded / 앞에서 지정\n",
    "\n",
    "sh_num_var = sh_num_var # 앞에서 지정\n",
    "\n",
    "drop_var =['dt_of_fr','fr_yn','id', 'emd_nm','year','day']\n",
    "\n",
    "\n",
    "\n",
    "select_var = (weather_var_1 + weather_var_2 + eg_var + lw_var + building_numeric_feature +\n",
    "             building_date + sh_num_var+ price_feature + sh_num_var + date_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urban_feature = ['mlt_us_yn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2 = train.drop(drop_var,axis=1)\n",
    "test_2 = test.drop(drop_var,axis=1)\n",
    "validation_2 = validation.drop(drop_var,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bldng_ar',\n",
       " 'ttl_ar',\n",
       " 'lnd_ar',\n",
       " 'dt_of_athrztn',\n",
       " 'tmprtr',\n",
       " 'prcpttn',\n",
       " 'wnd_spd',\n",
       " 'wnd_drctn',\n",
       " 'hmdt',\n",
       " 'gas_engry_us_201401',\n",
       " 'ele_engry_us_201401',\n",
       " 'gas_engry_us_201402',\n",
       " 'ele_engry_us_201402',\n",
       " 'gas_engry_us_201403',\n",
       " 'ele_engry_us_201403',\n",
       " 'gas_engry_us_201404',\n",
       " 'ele_engry_us_201404',\n",
       " 'gas_engry_us_201405',\n",
       " 'ele_engry_us_201405',\n",
       " 'gas_engry_us_201406',\n",
       " 'ele_engry_us_201406',\n",
       " 'gas_engry_us_201407',\n",
       " 'ele_engry_us_201407',\n",
       " 'gas_engry_us_201408',\n",
       " 'ele_engry_us_201408',\n",
       " 'gas_engry_us_201409',\n",
       " 'ele_engry_us_201409',\n",
       " 'gas_engry_us_201410',\n",
       " 'ele_engry_us_201410',\n",
       " 'gas_engry_us_201411',\n",
       " 'ele_engry_us_201411',\n",
       " 'gas_engry_us_201412',\n",
       " 'ele_engry_us_201412',\n",
       " 'gas_engry_us_201501',\n",
       " 'ele_engry_us_201501',\n",
       " 'gas_engry_us_201502',\n",
       " 'ele_engry_us_201502',\n",
       " 'gas_engry_us_201503',\n",
       " 'ele_engry_us_201503',\n",
       " 'gas_engry_us_201504',\n",
       " 'ele_engry_us_201504',\n",
       " 'gas_engry_us_201505',\n",
       " 'ele_engry_us_201505',\n",
       " 'gas_engry_us_201506',\n",
       " 'ele_engry_us_201506',\n",
       " 'gas_engry_us_201507',\n",
       " 'ele_engry_us_201507',\n",
       " 'gas_engry_us_201508',\n",
       " 'ele_engry_us_201508',\n",
       " 'gas_engry_us_201509',\n",
       " 'ele_engry_us_201509',\n",
       " 'gas_engry_us_201510',\n",
       " 'ele_engry_us_201510',\n",
       " 'gas_engry_us_201511',\n",
       " 'ele_engry_us_201511',\n",
       " 'gas_engry_us_201512',\n",
       " 'ele_engry_us_201512',\n",
       " 'gas_engry_us_201601',\n",
       " 'ele_engry_us_201601',\n",
       " 'gas_engry_us_201602',\n",
       " 'ele_engry_us_201602',\n",
       " 'gas_engry_us_201603',\n",
       " 'ele_engry_us_201603',\n",
       " 'gas_engry_us_201604',\n",
       " 'ele_engry_us_201604',\n",
       " 'gas_engry_us_201605',\n",
       " 'ele_engry_us_201605',\n",
       " 'gas_engry_us_201606',\n",
       " 'ele_engry_us_201606',\n",
       " 'gas_engry_us_201607',\n",
       " 'ele_engry_us_201607',\n",
       " 'gas_engry_us_201608',\n",
       " 'ele_engry_us_201608',\n",
       " 'gas_engry_us_201609',\n",
       " 'ele_engry_us_201609',\n",
       " 'gas_engry_us_201610',\n",
       " 'ele_engry_us_201610',\n",
       " 'gas_engry_us_201611',\n",
       " 'ele_engry_us_201611',\n",
       " 'gas_engry_us_201612',\n",
       " 'ele_engry_us_201612',\n",
       " 'gas_engry_us_201701',\n",
       " 'ele_engry_us_201701',\n",
       " 'gas_engry_us_201702',\n",
       " 'ele_engry_us_201702',\n",
       " 'gas_engry_us_201703',\n",
       " 'ele_engry_us_201703',\n",
       " 'gas_engry_us_201704',\n",
       " 'ele_engry_us_201704',\n",
       " 'gas_engry_us_201705',\n",
       " 'ele_engry_us_201705',\n",
       " 'gas_engry_us_201706',\n",
       " 'ele_engry_us_201706',\n",
       " 'gas_engry_us_201707',\n",
       " 'ele_engry_us_201707',\n",
       " 'gas_engry_us_201708',\n",
       " 'ele_engry_us_201708',\n",
       " 'gas_engry_us_201709',\n",
       " 'ele_engry_us_201709',\n",
       " 'gas_engry_us_201710',\n",
       " 'ele_engry_us_201710',\n",
       " 'gas_engry_us_201711',\n",
       " 'ele_engry_us_201711',\n",
       " 'gas_engry_us_201712',\n",
       " 'ele_engry_us_201712',\n",
       " 'gas_engry_us_201801',\n",
       " 'ele_engry_us_201801',\n",
       " 'gas_engry_us_201802',\n",
       " 'ele_engry_us_201802',\n",
       " 'gas_engry_us_201803',\n",
       " 'ele_engry_us_201803',\n",
       " 'gas_engry_us_201804',\n",
       " 'ele_engry_us_201804',\n",
       " 'gas_engry_us_201805',\n",
       " 'ele_engry_us_201805',\n",
       " 'gas_engry_us_201806',\n",
       " 'ele_engry_us_201806',\n",
       " 'gas_engry_us_201807',\n",
       " 'ele_engry_us_201807',\n",
       " 'gas_engry_us_201808',\n",
       " 'ele_engry_us_201808',\n",
       " 'gas_engry_us_201809',\n",
       " 'ele_engry_us_201809',\n",
       " 'gas_engry_us_201810',\n",
       " 'ele_engry_us_201810',\n",
       " 'gas_engry_us_201811',\n",
       " 'ele_engry_us_201811',\n",
       " 'gas_engry_us_201812',\n",
       " 'ele_engry_us_201812',\n",
       " 'lw_13101010',\n",
       " 'lw_13101110',\n",
       " 'lw_13101210',\n",
       " 'lw_13101211',\n",
       " 'lw_13101310',\n",
       " 'lw_13101410',\n",
       " 'lw_13111010',\n",
       " 'lw_13111110',\n",
       " 'lw_13121010',\n",
       " 'lw_13121011',\n",
       " 'lw_13131010',\n",
       " 'lw_13131110',\n",
       " 'lw_13141010',\n",
       " 'lw_13141011',\n",
       " 'hm_cnt',\n",
       " 'fr_sttn_dstnc',\n",
       " 'bldng_ar_prc',\n",
       " 'fr_wthr_fclt_dstnc',\n",
       " 'fr_mn_cnt',\n",
       " 'cctv_dstnc',\n",
       " 'fr_wthr_fclt_in_100m',\n",
       " 'cctv_in_100m',\n",
       " 'tbc_rtl_str_dstnc',\n",
       " 'sft_emrgnc_bll_dstnc',\n",
       " 'ahsm_dstnc',\n",
       " 'no_tbc_zn_dstnc',\n",
       " 'bldng_cnt_in_50m',\n",
       " 'month_1',\n",
       " 'month_2',\n",
       " 'month_3',\n",
       " 'month_4',\n",
       " 'month_5',\n",
       " 'month_6',\n",
       " 'month_7',\n",
       " 'month_8',\n",
       " 'month_9',\n",
       " 'month_10',\n",
       " 'month_11',\n",
       " 'month_12',\n",
       " 'weekday_0',\n",
       " 'weekday_1',\n",
       " 'weekday_2',\n",
       " 'weekday_3',\n",
       " 'weekday_4',\n",
       " 'weekday_5',\n",
       " 'weekday_6',\n",
       " 'season_0',\n",
       " 'season_1',\n",
       " 'season_2',\n",
       " 'season_3',\n",
       " 'hour_0',\n",
       " 'hour_1',\n",
       " 'hour_2',\n",
       " 'hour_3',\n",
       " 'hour_4',\n",
       " 'hour_5',\n",
       " 'hour_6',\n",
       " 'hour_7',\n",
       " 'hour_8',\n",
       " 'hour_9',\n",
       " 'hour_10',\n",
       " 'hour_11',\n",
       " 'hour_12',\n",
       " 'hour_13',\n",
       " 'hour_14',\n",
       " 'hour_15',\n",
       " 'hour_16',\n",
       " 'hour_17',\n",
       " 'hour_18',\n",
       " 'hour_19',\n",
       " 'hour_20',\n",
       " 'hour_21',\n",
       " 'hour_22',\n",
       " 'hour_23',\n",
       " 'blank',\n",
       " '개발제한구역',\n",
       " '계획관리지역',\n",
       " '관리지역',\n",
       " '근린상업지역',\n",
       " '농림지역',\n",
       " '보전관리지역',\n",
       " '보전녹지지역',\n",
       " '생산관리지역',\n",
       " '생산녹지지역',\n",
       " '용도미지정',\n",
       " '유통상업지역',\n",
       " '일반공업지역',\n",
       " '일반상업지역',\n",
       " '자연녹지지역',\n",
       " '자연환경보전지역',\n",
       " '제1종일반주거지역',\n",
       " '제1종전용주거지역',\n",
       " '제2종일반주거지역',\n",
       " '제2종전용주거지역',\n",
       " '제3종일반주거지역',\n",
       " '준공업지역',\n",
       " '준주거지역',\n",
       " '중심상업지역',\n",
       " '공',\n",
       " '과',\n",
       " '구',\n",
       " '답',\n",
       " '대',\n",
       " '도',\n",
       " '목',\n",
       " '묘',\n",
       " '사',\n",
       " '수',\n",
       " '양',\n",
       " '원',\n",
       " '유',\n",
       " '임',\n",
       " '잡',\n",
       " '장',\n",
       " '전',\n",
       " '제',\n",
       " '종',\n",
       " '주',\n",
       " '차',\n",
       " '창',\n",
       " '천',\n",
       " '철',\n",
       " '체',\n",
       " '학',\n",
       " 'blank',\n",
       " '경마장',\n",
       " '고속도로휴게소',\n",
       " '골프장 대중제',\n",
       " '골프장 회원제',\n",
       " '공업기타',\n",
       " '공업나지',\n",
       " '공업용',\n",
       " '공원등',\n",
       " '공원묘지',\n",
       " '과수원',\n",
       " '기타',\n",
       " '다세대',\n",
       " '단독',\n",
       " '답',\n",
       " '답기타',\n",
       " '도로등',\n",
       " '목장용지',\n",
       " '발전소',\n",
       " '상업기타',\n",
       " '상업나지',\n",
       " '상업용',\n",
       " '스키장',\n",
       " '아파트',\n",
       " '업무용',\n",
       " '여객자동차터미널',\n",
       " '연립',\n",
       " '운동장등',\n",
       " '위험시설',\n",
       " '유원지',\n",
       " '유해.혐오시설',\n",
       " '임야기타',\n",
       " '자연림',\n",
       " '전',\n",
       " '전기타',\n",
       " '조림',\n",
       " '주거기타',\n",
       " '주거나지',\n",
       " '주상기타',\n",
       " '주상나지',\n",
       " '주상용',\n",
       " '주차장등',\n",
       " '콘도미니엄',\n",
       " '토지임야',\n",
       " '특수기타',\n",
       " '하천등',\n",
       " 'blank',\n",
       " '광대로한면',\n",
       " '광대세각',\n",
       " '광대소각',\n",
       " '맹지',\n",
       " '세로각지(가)',\n",
       " '세로각지(불)',\n",
       " '세로한면(가)',\n",
       " '세로한면(불)',\n",
       " '소로각지',\n",
       " '소로한면',\n",
       " '중로각지',\n",
       " '중로한면',\n",
       " '지정되지않음',\n",
       " 'blank',\n",
       " '공공용시설',\n",
       " '공동주택',\n",
       " '공장',\n",
       " '관광휴게시설',\n",
       " '교육연구및복지시설',\n",
       " '교육연구시설',\n",
       " '교정및군사시설',\n",
       " '근린생활시설',\n",
       " '노유자시설',\n",
       " '단독주택',\n",
       " '동.식물 관련시설',\n",
       " '묘지관련시설',\n",
       " '문화및집회시설',\n",
       " '발전시설',\n",
       " '방송통신시설',\n",
       " '분뇨.쓰레기처리시설',\n",
       " '수련시설',\n",
       " '숙박시설',\n",
       " '시장',\n",
       " '업무시설',\n",
       " '운동시설',\n",
       " '운수시설',\n",
       " '위락시설',\n",
       " '위험물저장및처리시설',\n",
       " '의료시설',\n",
       " '자동차관련시설',\n",
       " '장례식장',\n",
       " '제1종근린생활시설',\n",
       " '제2종근린생활시설',\n",
       " '종교시설',\n",
       " '창고시설',\n",
       " '파출소',\n",
       " '판매및영업시설',\n",
       " '판매시설',\n",
       " 'blank',\n",
       " '강파이프구조',\n",
       " '경량철골구조',\n",
       " '기타강구조',\n",
       " '기타구조',\n",
       " '기타조적구조',\n",
       " '기타콘크리트구조',\n",
       " '목구조',\n",
       " '벽돌구조',\n",
       " '블록구조',\n",
       " '석구조',\n",
       " '일반목구조',\n",
       " '일반철골구조',\n",
       " '조적구조',\n",
       " '철골철근콘크리트구조',\n",
       " '철골콘크리트구조',\n",
       " '철근콘크리트구조',\n",
       " '통나무구조',\n",
       " '프리케스트콘크리트구조',\n",
       " 'blank',\n",
       " '공공용',\n",
       " '공업용',\n",
       " '기타',\n",
       " '농수산용',\n",
       " '문교사회용',\n",
       " '상업용',\n",
       " '주거용',\n",
       " -999.0,\n",
       " 0.0,\n",
       " 10.0,\n",
       " 20.0,\n",
       " 30.0,\n",
       " 40.0,\n",
       " 55.0,\n",
       " 56.0,\n",
       " -999.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 10.0,\n",
       " 20.0,\n",
       " 21.0,\n",
       " 5,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 31,\n",
       " 'urban_Y',\n",
       " 'N',\n",
       " 'Y',\n",
       " '11층이상',\n",
       " 'blank',\n",
       " '견본주택(모델하우스)',\n",
       " '공동주택(주택법시행령제63조제1항각호1에해당)',\n",
       " '기타',\n",
       " '기타(가설건축물분류)',\n",
       " '민박7실이상',\n",
       " '민박7실이하',\n",
       " '스프링클러,물분무등설치대상',\n",
       " '연면적 15,000 이상',\n",
       " '옥내소화전설치대상',\n",
       " '일반대상물',\n",
       " '임시사무실,창고,숙소',\n",
       " '자동화재탐지설치대상',\n",
       " '주거용비닐하우스',\n",
       " '콘테이너하우스',\n",
       " '펜션7실이상',\n",
       " '펜션7실이하',\n",
       " 'N',\n",
       " 'blank',\n",
       " 'N',\n",
       " 'blank',\n",
       " 'N',\n",
       " 'T',\n",
       " 'Y',\n",
       " 'blank',\n",
       " 'N',\n",
       " 'Y',\n",
       " 'blank',\n",
       " 'N',\n",
       " 'blank',\n",
       " 'N',\n",
       " 'Y',\n",
       " 'blank',\n",
       " 'N',\n",
       " 'Y',\n",
       " 'blank']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "Name: month_1, dtype: uint8"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_2.iloc[0:3,156]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 0~155번까지 변수는 파이프라인 탈 변수들 -> train_2, validation_2, test_2\n",
    "##### 뒤 부분(156~ 변수들)은 모두 pandas에서 미리 원핫처리해준 변수들 -> train_3, validation_3, test_3\n",
    "##### 마지막에 np.c_[dataset_2,dataset_3] 로 합친 뒤 모델에 투입\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3 = np.array(train_2.iloc[:,156:])\n",
    "test_3 = np.array(test_2.iloc[:,156:])\n",
    "validation_3 = np.array(validation_2.iloc[:,156:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Pipeline\n",
    "\n",
    "##### 'tmprtr','prcpttn','wnd_spd','wnd_drctn','hmdt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_imputer = ColumnTransformer([\n",
    "    ('prcpttn_imputer',SimpleImputer(strategy='constant',fill_value=-1),weather_var_1),\n",
    "    ('otehrs_imputer',IterativeImputer(),weather_var_2)\n",
    "     ])\n",
    "\n",
    "weather_scale_PCA = Pipeline([\n",
    "    ('Scaler',StandardScaler()),\n",
    "    ('PCA',PCA())\n",
    "])\n",
    "\n",
    "weather_pipe = Pipeline([\n",
    "    ('weather_imputer',weather_imputer),\n",
    "    ('weather_scale_PCA',weather_scale_PCA)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gas, Ele, Lw Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  불이 난 달의 Gas와 Ele 사용량을 열으로 추가하는 변환기를 정의합니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "class TrFmGEAdder(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, index = eg_var):\n",
    "    self.index = ['dt_of_fr'] + index\n",
    "  \n",
    "  def fit(self, X,y = None):\n",
    "    return(self)\n",
    "  \n",
    "  def transform(self, X, y = None):\n",
    "    index = self.index\n",
    "    X = np.append(np.array(train['dt_of_fr']).reshape(-1,1), X, axis = 1) # X를 받아서 앞에 dt_of_fr열을 추가합니다.\n",
    "    X = pd.DataFrame(X) # 차후 열 이름을 기준으로 사용해야 하기 때문에 Pandas로 변환합니다. \n",
    "    X.columns = train[['dt_of_fr']+eg_var].keys() # 열 이름을 추가합니다. eg_var 대상으로 진행할 것이기 때문에 이렇게 씁니다.\n",
    "\n",
    "    train_rst = X.assign(\n",
    "        fr_month_gas  = 'gas'+X['dt_of_fr'].str.slice_replace(start=7, stop=20, repl='').str.replace(pat='-', repl='', regex=False)\n",
    "        ).assign(\n",
    "            fr_month_ele  = 'ele'+X['dt_of_fr'].str.slice_replace(start=7, stop=20, repl='').str.replace(pat='-', repl='', regex=False)\n",
    "            ) # gas/ele + 불이 난 달을 값으로 갖는 열을 생성합니다. 이걸 생성하지 않고 하는 것도 할 수 있을거 같은데 지금은 뇌가 멈췄으니 일단 만듭니다.\n",
    "    \n",
    "    tk = train_rst.keys()[np.where(pd.Series(train_rst.keys()) == index[0])[0][0]:np.where(pd.Series(train_rst.keys()) == index[-1])[0][0]+1]\n",
    "    keys = pd.Series(tk).str.split('_', expand = True).iloc[:,[0,3]]\n",
    "    keys[1] = keys[0]+keys[3]\n",
    "    keys[1][0] = 'dt_of_fr' # 변경된 열 이름의 리스트입니다. 가장 앞의 값이 누락되어서 추가해주었습니다.\n",
    "    \n",
    "    coln = keys[1].ravel().tolist()+['fr_month_gas','fr_month_ele'] #열 이름을 바꿔줄 준비. 앞선 fr_month_gas/ ele열을 index로 사용하기 위함입니다\n",
    "    train_rst.columns = coln #열 이름 변경합니다.\n",
    "\n",
    "    fm_gas_index = train_rst.fr_month_gas.map(lambda x: np.where(x == train_rst.keys())[0][0]) # 불이 난 월의 gas의 열 index\n",
    "    fm_ele_index = train_rst.fr_month_ele.map(lambda x: np.where(x == train_rst.keys())[0][0]) # 불이 난 월의 ele의 열 index\n",
    "\n",
    "    train_eg = train_rst.assign(\n",
    "        gas_fm = np.array(train_rst)[np.arange(train.shape[0]),fm_gas_index.values] # 최종적으로 두 index를 기준으로 값을 대입합니다.\n",
    "        ).assign(\n",
    "            ele_fm = np.array(train_rst)[np.arange(train.shape[0]),fm_ele_index.values]\n",
    "            )[['gas_fm','ele_fm']] # 이 두 열만 남기거나\n",
    "            #.drop(['fr_month_gas','fr_month_ele','dt_of_fr'], axis = 1) # 이 두 열을 더하거나. 일단은 두 열만 남겼습니다. \n",
    "    \n",
    "    return np.array(train_eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Val. \n",
    "\n",
    "class VFmGEAdder(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, index = eg_var):\n",
    "    self.index = ['dt_of_fr'] + index\n",
    "  \n",
    "  def fit(self, X,y = None):\n",
    "    return(self)\n",
    "  \n",
    "  def transform(self, X, y = None):\n",
    "    index = self.index\n",
    "    X = np.append(np.array(validation['dt_of_fr']).reshape(-1,1), X, axis = 1) # X를 받아서 앞에 dt_of_fr열을 추가합니다.\n",
    "    X = pd.DataFrame(X) # 차후 열 이름을 기준으로 사용해야 하기 때문에 Pandas로 변환합니다. \n",
    "    X.columns = validation[['dt_of_fr']+eg_var].keys() # 열 이름을 추가합니다. eg_var 대상으로 진행할 것이기 때문에 이렇게 씁니다.\n",
    "\n",
    "    train_rst = X.assign(\n",
    "        fr_month_gas  = 'gas'+X['dt_of_fr'].str.slice_replace(start=7, stop=20, repl='').str.replace(pat='-', repl='', regex=False)\n",
    "        ).assign(\n",
    "            fr_month_ele  = 'ele'+X['dt_of_fr'].str.slice_replace(start=7, stop=20, repl='').str.replace(pat='-', repl='', regex=False)\n",
    "            ) # gas/ele + 불이 난 달을 값으로 갖는 열을 생성합니다. 이걸 생성하지 않고 하는 것도 할 수 있을거 같은데 지금은 뇌가 멈췄으니 일단 만듭니다.\n",
    "    \n",
    "    tk = train_rst.keys()[np.where(pd.Series(train_rst.keys()) == index[0])[0][0]:np.where(pd.Series(train_rst.keys()) == index[-1])[0][0]+1]\n",
    "    keys = pd.Series(tk).str.split('_', expand = True).iloc[:,[0,3]]\n",
    "    keys[1] = keys[0]+keys[3]\n",
    "    keys[1][0] = 'dt_of_fr' # 변경된 열 이름의 리스트입니다. 가장 앞의 값이 누락되어서 추가해주었습니다.\n",
    "    \n",
    "    coln = keys[1].ravel().tolist()+['fr_month_gas','fr_month_ele'] #열 이름을 바꿔줄 준비. 앞선 fr_month_gas/ ele열을 index로 사용하기 위함입니다\n",
    "    train_rst.columns = coln #열 이름 변경합니다.\n",
    "\n",
    "    fm_gas_index = train_rst.fr_month_gas.map(lambda x: np.where(x == train_rst.keys())[0][0]) # 불이 난 월의 gas의 열 index\n",
    "    fm_ele_index = train_rst.fr_month_ele.map(lambda x: np.where(x == train_rst.keys())[0][0]) # 불이 난 월의 ele의 열 index\n",
    "\n",
    "    train_eg = train_rst.assign(\n",
    "        gas_fm = np.array(train_rst)[np.arange(validation.shape[0]),fm_gas_index.values] # 최종적으로 두 index를 기준으로 값을 대입합니다.\n",
    "        ).assign(\n",
    "            ele_fm = np.array(train_rst)[np.arange(validation.shape[0]),fm_ele_index.values]\n",
    "            )[['gas_fm','ele_fm']] # 이 두 열만 남기거나\n",
    "            #.drop(['fr_month_gas','fr_month_ele','dt_of_fr'], axis = 1) # 이 두 열을 더하거나. 일단은 두 열만 남겼습니다. \n",
    "    \n",
    "    return np.array(train_eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "\n",
    "class TeFmGEAdder(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, index = eg_var):\n",
    "    self.index = ['dt_of_fr'] + index\n",
    "  \n",
    "  def fit(self, X,y = None):\n",
    "    return(self)\n",
    "  \n",
    "  def transform(self, X, y = None):\n",
    "    index = self.index\n",
    "    X = np.append(np.array(test['dt_of_fr']).reshape(-1,1), X, axis = 1) # X를 받아서 앞에 dt_of_fr열을 추가합니다.\n",
    "    X = pd.DataFrame(X) # 차후 열 이름을 기준으로 사용해야 하기 때문에 Pandas로 변환합니다. \n",
    "    X.columns = test[['dt_of_fr']+eg_var].keys() # 열 이름을 추가합니다. eg_var 대상으로 진행할 것이기 때문에 이렇게 씁니다.\n",
    "\n",
    "    train_rst = X.assign(\n",
    "        fr_month_gas  = 'gas'+X['dt_of_fr'].str.slice_replace(start=7, stop=20, repl='').str.replace(pat='-', repl='', regex=False)\n",
    "        ).assign(\n",
    "            fr_month_ele  = 'ele'+X['dt_of_fr'].str.slice_replace(start=7, stop=20, repl='').str.replace(pat='-', repl='', regex=False)\n",
    "            ) # gas/ele + 불이 난 달을 값으로 갖는 열을 생성합니다. 이걸 생성하지 않고 하는 것도 할 수 있을거 같은데 지금은 뇌가 멈췄으니 일단 만듭니다.\n",
    "    \n",
    "    tk = train_rst.keys()[np.where(pd.Series(train_rst.keys()) == index[0])[0][0]:np.where(pd.Series(train_rst.keys()) == index[-1])[0][0]+1]\n",
    "    keys = pd.Series(tk).str.split('_', expand = True).iloc[:,[0,3]]\n",
    "    keys[1] = keys[0]+keys[3]\n",
    "    keys[1][0] = 'dt_of_fr' # 변경된 열 이름의 리스트입니다. 가장 앞의 값이 누락되어서 추가해주었습니다.\n",
    "    \n",
    "    coln = keys[1].ravel().tolist()+['fr_month_gas','fr_month_ele'] #열 이름을 바꿔줄 준비. 앞선 fr_month_gas/ ele열을 index로 사용하기 위함입니다\n",
    "    train_rst.columns = coln #열 이름 변경합니다.\n",
    "\n",
    "    fm_gas_index = train_rst.fr_month_gas.map(lambda x: np.where(x == train_rst.keys())[0][0]) # 불이 난 월의 gas의 열 index\n",
    "    fm_ele_index = train_rst.fr_month_ele.map(lambda x: np.where(x == train_rst.keys())[0][0]) # 불이 난 월의 ele의 열 index\n",
    "\n",
    "    train_eg = train_rst.assign(\n",
    "        gas_fm = np.array(train_rst)[np.arange(test.shape[0]),fm_gas_index.values] # 최종적으로 두 index를 기준으로 값을 대입합니다.\n",
    "        ).assign(\n",
    "            ele_fm = np.array(train_rst)[np.arange(test.shape[0]),fm_ele_index.values]\n",
    "            )[['gas_fm','ele_fm']] # 이 두 열만 남기거나\n",
    "            #.drop(['fr_month_gas','fr_month_ele','dt_of_fr'], axis = 1) # 이 두 열을 더하거나. 일단은 두 열만 남겼습니다. \n",
    "    \n",
    "    return np.array(train_eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names=attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "# 왜인지는 모르겠는데 full_pipeline을 만들 때 ColumnTransformer는 자꾸 에러가 나서 FeatureUnion을 쓰려고 DataFramseSelector를 정의해 주었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## urban_population_feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "urban_transformer = Pipeline(steps = [\n",
    "    ('constant', SimpleImputer(strategy = 'most_frequent')),\n",
    "    ('OneHotEncoer', OneHotEncoder())\n",
    "])\n",
    "'''\n",
    "\n",
    "numerical_transformer = Pipeline([\n",
    "    ('scaling', StandardScaler())\n",
    "])\n",
    "\n",
    "price_transformer = Pipeline(steps = [\n",
    "    ('median', SimpleImputer(strategy = 'median')),\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "])\n",
    "\n",
    "processor_1 = ColumnTransformer(\n",
    "    transformers = [\n",
    "    #('urb', urban_transformer, urban_feature),\n",
    "    ('num', numerical_transformer,sh_num_var),\n",
    "    ('price', price_transformer, price_feature)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building_feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_numeric_transformer = Pipeline(steps = [\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "])\n",
    "\n",
    "\n",
    "building_date_transformer = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy = 'constant', fill_value = 0))\n",
    "])\n",
    "\n",
    "\n",
    "processor_2 = ColumnTransformer(\n",
    "    transformers = [\n",
    "    ('bldng_num', building_numeric_transformer, building_numeric_feature),\n",
    "    ('bldng_date', building_date_transformer, building_date)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTregl_pipe = FeatureUnion(transformer_list = [\\n                                            ('eg_imputer', Treg_imputer),\\n                                            ('lw_imputer', lw_imputer)\\n                     ])\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "Treg_imputer = Pipeline([\n",
    "                       ('selector', DataFrameSelector(eg_var)),\n",
    "                       ('zero_imputer', SimpleImputer(strategy='constant',fill_value=0)),\n",
    "                       ('scaler', StandardScaler()),\n",
    "                       ('fire month gas ele adder', TrFmGEAdder())\n",
    "])\n",
    "\n",
    "lw_imputer = Pipeline([\n",
    "                      ('selector', DataFrameSelector(lw_var)),\n",
    "                      ('zero_imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "                      ('scaler', StandardScaler())\n",
    "])\n",
    "'''\n",
    "Tregl_pipe = FeatureUnion(transformer_list = [\n",
    "                                            ('eg_imputer', Treg_imputer),\n",
    "                                            ('lw_imputer', lw_imputer)\n",
    "                     ])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nVegl_pipe = FeatureUnion(transformer_list = [\\n                                            ('eg_imputer', Veg_imputer),\\n                                            ('lw_imputer', lw_imputer)\\n                     ])\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation\n",
    "Veg_imputer = Pipeline([\n",
    "                       ('selector', DataFrameSelector(eg_var)),\n",
    "                       ('zero_imputer', SimpleImputer(strategy='constant',fill_value=0)),\n",
    "                       ('scaler', StandardScaler()),\n",
    "                       ('fire month gas ele adder', VFmGEAdder())\n",
    "])\n",
    "\n",
    "lw_imputer = Pipeline([\n",
    "                      ('selector', DataFrameSelector(lw_var)),\n",
    "                      ('zero_imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "                      ('scaler', StandardScaler())\n",
    "])\n",
    "'''\n",
    "Vegl_pipe = FeatureUnion(transformer_list = [\n",
    "                                            ('eg_imputer', Veg_imputer),\n",
    "                                            ('lw_imputer', lw_imputer)\n",
    "                     ])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTeegl_pipe = FeatureUnion(transformer_list = [\\n                                            ('eg_imputer', Teeg_imputer),\\n                                            ('lw_imputer', lw_imputer)\\n                     ])\\n\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "Teeg_imputer = Pipeline([\n",
    "                       ('selector', DataFrameSelector(eg_var)),\n",
    "                       ('zero_imputer', SimpleImputer(strategy='constant',fill_value=0)),\n",
    "                       ('scaler', StandardScaler()),\n",
    "                       ('fire month gas ele adder', TeFmGEAdder())\n",
    "])\n",
    "\n",
    "lw_imputer = Pipeline([\n",
    "                      ('selector', DataFrameSelector(lw_var)),\n",
    "                      ('zero_imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "                      ('scaler', StandardScaler())\n",
    "])\n",
    "'''\n",
    "Teegl_pipe = FeatureUnion(transformer_list = [\n",
    "                                            ('eg_imputer', Teeg_imputer),\n",
    "                                            ('lw_imputer', lw_imputer)\n",
    "                     ])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최종적으로 모델에 들어가는 모양"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_full_pipe = FeatureUnion(transformer_list = [\n",
    "    ('weather',weather_pipe ),\n",
    "    ('eg_imputer', Treg_imputer),\n",
    "    ('lw_impute', lw_imputer),\n",
    "    ('processor_1', processor_1),\n",
    "    ('processor_2', processor_2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation_full_pipe = FeatureUnion(transformer_list = [\n",
    "    ('weather',weather_pipe ),\n",
    "    ('eg_imputer', Veg_imputer),\n",
    "    ('lw_impute', lw_imputer),\n",
    "    ('processor_1', processor_1),\n",
    "    ('processor_2', processor_2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_full_pipe = FeatureUnion(transformer_list = [\n",
    "    ('weather',weather_pipe ),\n",
    "    ('eg_imputer', Teeg_imputer),\n",
    "    ('lw_impute', lw_imputer),\n",
    "    ('processor_1', processor_1),\n",
    "    ('processor_2', processor_2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model에 들어갈 데이터 최종적 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 그냥 돌리면 시간이 너무 많이 걸리니까 완성된 array를 밖에 저장해서 colab에서 돌리자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Train_X = Train_full_pipe.fit_transform(train_2)\n",
    "Validation_X = Validation_full_pipe.fit_transform(validation_2)\n",
    "Test_X = Test_full_pipe.fit_transform(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X = np.c_[Train_X,train_3]\n",
    "Validation_X = np.c_[Validation_X,validation_3]\n",
    "Test_X = np.c_[Test_X,test_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_y = np.array(train.fr_yn).ravel()\n",
    "Validation_y = np.array(validation.fr_yn).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59199, 317)\n",
      "(2957, 317)\n",
      "(6898, 317)\n"
     ]
    }
   ],
   "source": [
    "print(Train_X.shape)\n",
    "print(Test_X.shape)\n",
    "print(Validation_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ieunpyo/PycharmProjects/Kaggle/gimhae_fire/Train_X'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_dir+'Train_X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(work_dir+'Train_X',Train_X,allow_pickle=True) \n",
    "np.save(work_dir+'Test_X',Test_X,allow_pickle=True) \n",
    "np.save(work_dir+'Validation_X',Validation_X,allow_pickle=True) \n",
    "\n",
    "np.save(work_dir+'Train_y',Train_y,allow_pickle=True) \n",
    "np.save(work_dir+'Validation_y',Validation_y,allow_pickle=True) \n",
    "\n",
    "# 불러올 때는 np.load('D:/admin/Documents/x_save.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "RF_clf = RandomForestClassifier()\n",
    "\n",
    "record_t = []\n",
    "for i in range(50) :\n",
    "    RF_clf.fit(Train_X,Train_y)\n",
    "    record_t.append(f1_score(Validation_y.reshape(-1), RF_clf.predict(Validation_X)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3493761140819964,\n",
       " 0.28183361629881154,\n",
       " 0.306854289605084,\n",
       " 0.28703703703703703,\n",
       " 0.3225538971807628,\n",
       " 0.34420289855072467,\n",
       " 0.3007590132827324,\n",
       " 0.32846087704213245,\n",
       " 0.3327495621716287,\n",
       " 0.31722880583409296,\n",
       " 0.3165399239543727,\n",
       " 0.32021709633649936,\n",
       " 0.3105263157894737,\n",
       " 0.33059885151763735,\n",
       " 0.33133047210300426,\n",
       " 0.3305936073059361,\n",
       " 0.3220338983050848,\n",
       " 0.3290004482294935,\n",
       " 0.3237759153065726,\n",
       " 0.2912621359223301]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31884673879277037"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015667428342703505"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*np.std(record)/np.sqrt(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31258991975753175"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(record_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3494071146245059,\n",
       " 0.37938144329896906,\n",
       " 0.3479328694228408,\n",
       " 0.34425549564496055,\n",
       " 0.3660237997537957,\n",
       " 0.30821626223925075,\n",
       " 0.33765073693613223,\n",
       " 0.29828850855745725,\n",
       " 0.318625174175569,\n",
       " 0.3123715577476367,\n",
       " 0.32343499197431785,\n",
       " 0.2985493682732803,\n",
       " 0.3324915824915825,\n",
       " 0.35040895393887217,\n",
       " 0.3494897959183673,\n",
       " 0.37080867850098614,\n",
       " 0.3361569326794472,\n",
       " 0.3540983606557377,\n",
       " 0.31505728314238957,\n",
       " 0.34982935153583616]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3371239130755968"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(record_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3590844062947067,\n",
       " 0.31574279379157427,\n",
       " 0.3567688855646971,\n",
       " 0.34170440510498146,\n",
       " 0.3446909667194929,\n",
       " 0.3463510848126233,\n",
       " 0.34155184916606235,\n",
       " 0.36110034870205343,\n",
       " 0.3571727310748641,\n",
       " 0.30837717523269936,\n",
       " 0.3341213553979512,\n",
       " 0.3652545389818441,\n",
       " 0.34092634776006076,\n",
       " 0.34291954859847107,\n",
       " 0.372359470103831,\n",
       " 0.3705148205928237,\n",
       " 0.35179856115107916,\n",
       " 0.33362753751103263,\n",
       " 0.36500395882818687,\n",
       " 0.3346908552388004]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34718808203139184"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(record_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38267451640033645,\n",
       " 0.35823849579416134,\n",
       " 0.3643617021276596,\n",
       " 0.39232781168265035,\n",
       " 0.3836772983114447,\n",
       " 0.35825105782792666,\n",
       " 0.3754333828628034,\n",
       " 0.37999159310634717,\n",
       " 0.35617760617760613,\n",
       " 0.4064544265154819,\n",
       " 0.38073182028716995,\n",
       " 0.3963963963963964,\n",
       " 0.39358187824445495,\n",
       " 0.38025594149908587,\n",
       " 0.38426349496797807,\n",
       " 0.38343685300207037,\n",
       " 0.37992831541218636,\n",
       " 0.38629283489096566,\n",
       " 0.36832895888013995,\n",
       " 0.3331603528801246]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_5_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37719823686334947"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(record_5_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3531786074672048,\n",
       " 0.3857965451055662,\n",
       " 0.3585217870932157,\n",
       " 0.35036496350364965,\n",
       " 0.3971702880242547,\n",
       " 0.37099316868103,\n",
       " 0.36991241628026794,\n",
       " 0.3869653767820774,\n",
       " 0.3777437468095967,\n",
       " 0.3698556921432389,\n",
       " 0.366943866943867,\n",
       " 0.38504672897196257,\n",
       " 0.38100208768267224,\n",
       " 0.36670293797606096,\n",
       " 0.37940094587493434,\n",
       " 0.38801422041645506,\n",
       " 0.3745435576421492,\n",
       " 0.36170212765957444,\n",
       " 0.37678100263852243,\n",
       " 0.3618677042801556]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_5_30_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37312538859882277"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(record_5_30_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2867546654528903,\n",
       " 0.3255813953488372,\n",
       " 0.3245454545454545,\n",
       " 0.34471803018268465,\n",
       " 0.3286467486818981,\n",
       " 0.27458432304038005,\n",
       " 0.29533429533429534,\n",
       " 0.33037156704361875,\n",
       " 0.32465688594415526,\n",
       " 0.3322939866369711,\n",
       " 0.33002159827213823,\n",
       " 0.32417829806393517,\n",
       " 0.32375055285272,\n",
       " 0.3099293726630661,\n",
       " 0.32872655478775914,\n",
       " 0.3127490039840637,\n",
       " 0.29609929078014185,\n",
       " 0.3012987012987013,\n",
       " 0.2655771195097038,\n",
       " 0.31284046692607004]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3232421875,\n",
       " 0.35955056179775285,\n",
       " 0.3467297084318361,\n",
       " 0.3542157324540744,\n",
       " 0.31382113821138213,\n",
       " 0.313173933427098,\n",
       " 0.32349272349272346,\n",
       " 0.3207070707070707,\n",
       " 0.3171127331711273,\n",
       " 0.3262764632627646,\n",
       " 0.32319564230594644,\n",
       " 0.3140794223826715,\n",
       " 0.3341176470588235,\n",
       " 0.3553054662379421,\n",
       " 0.31976744186046513,\n",
       " 0.37669376693766937,\n",
       " 0.3100909484625379,\n",
       " 0.27861665854846573,\n",
       " 0.33045622688039455,\n",
       " 0.3327541268462207,\n",
       " 0.2933723196881092,\n",
       " 0.33856597369537544,\n",
       " 0.3386046511627907,\n",
       " 0.3346938775510204,\n",
       " 0.2966292134831461,\n",
       " 0.32194244604316546,\n",
       " 0.34038950042336996,\n",
       " 0.32714717306862323,\n",
       " 0.3051305130513052,\n",
       " 0.30388109000825764,\n",
       " 0.33126110124333924,\n",
       " 0.3289841565703635,\n",
       " 0.3592233009708738,\n",
       " 0.3296422487223169,\n",
       " 0.30990833697075515,\n",
       " 0.30332209918151176,\n",
       " 0.3610648918469218,\n",
       " 0.3159768580329328,\n",
       " 0.34838709677419355,\n",
       " 0.320392681838465,\n",
       " 0.3203836930455635,\n",
       " 0.3493761140819964,\n",
       " 0.29836629406706794,\n",
       " 0.3404642694583523,\n",
       " 0.31393643031784846,\n",
       " 0.30666108085462923,\n",
       " 0.26592282659228267,\n",
       " 0.3474576271186441,\n",
       " 0.33348644924207627,\n",
       " 0.3445447087776866]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32605037247719904"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(record_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  1,  3,  6, 10, 10,  8,  6,  4,  1]),\n",
       " array([0.26592283, 0.27699992, 0.28807701, 0.29915411, 0.3102312 ,\n",
       "        0.3213083 , 0.33238539, 0.34346248, 0.35453958, 0.36561667,\n",
       "        0.37669377]))"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(record_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  1.,  3.,  6., 10., 10.,  8.,  6.,  4.,  1.]),\n",
       " array([0.26592283, 0.27699992, 0.28807701, 0.29915411, 0.3102312 ,\n",
       "        0.3213083 , 0.33238539, 0.34346248, 0.35453958, 0.36561667,\n",
       "        0.37669377]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(record_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3136329155674742"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(record_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00041397959960555176"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(record_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3132140898522523"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(record_100)-1.96*np.sqrt(np.var(record_t))/(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3140517412826961"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(record_100)+1.96*np.sqrt(np.var(record_t))/(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_clf = RandomForestClassifier(min_samples_leaf=10)\n",
    "#'criterion': 'gini'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.fit(Train_X,Train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.906332877244548"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(RF_clf.predict(Train_X)==Train_y.reshape(-1))/len(Train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8206726587416643"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(RF_clf.predict(Validation_X)==Validation_y.reshape(-1))/len(Validation_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4778227705056973"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Train_y.reshape(-1), RF_clf.predict(Train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29675952245594084"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Validation_y.reshape(-1), RF_clf.predict(Validation_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위를 보면 엄청나게 오버피팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ieunpyo/anaconda3/envs/work/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-294ba991253f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_f_for_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.41\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mRF_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnew_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mValidation_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRF_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mValidation_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_f_for_fun\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "max_f_for_fun = 0.41\n",
    "for i in range(200) :\n",
    "    RF_clf.fit(Train_X,Train_y)\n",
    "    new_score = f1_score(Validation_y.reshape(-1), RF_clf.predict(Validation_X))\n",
    "    if new_score > max_f_for_fun :\n",
    "        train_f_score = f1_score(Train_y.reshape(-1), RF_clf.predict(Train_X))\n",
    "        max_f_for_fun = new_score\n",
    "        submission = RF_clf.predict(Test_X)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(train_f_score)\n",
    "print(max_f_for_fun)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Hyperparameter Grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators,max_features,max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf_clf, param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "rf_random.fit(Train_X, Train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(Validation_y.reshape(-1),rf_random.predict(Validation_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(Train_y.reshape(-1), RF_clf.predict(Train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission = RF_clf.predict(Test_X)\n",
    "submission = pd.DataFrame(submission,columns=['fr_yn'])\n",
    "submission['fr_yn'] = submission['fr_yn'].map({1:'Y', 0:'N'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('화재예측과제_Submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['urban']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
